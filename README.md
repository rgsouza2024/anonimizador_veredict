# Anonimizador Veredict

**Vers√£o 1.1 (Beta)**

Desenvolvido por: Juiz Federal Rodrigo Gon√ßalves de Souza

---

## Sum√°rio

O Anonimizador Veredict √© uma ferramenta avan√ßada e flex√≠vel, desenvolvida em Python com Streamlit, para auxiliar na anonimiza√ß√£o de documentos jur√≠dicos. O projeto emprega uma t√©cnica de **Anonimiza√ß√£o em Duas Camadas**: a primeira camada realiza uma anonimiza√ß√£o determin√≠stica e controlada de Informa√ß√µes Pessoais Identific√°veis (PII) usando Presidio Analyzer e spaCy; a segunda camada, opcional, utiliza um Modelo de Linguagem Grande (LLM) √† escolha do usu√°rio para reescrever o texto anonimizado, gerando um resumo jur√≠dico detalhado, fluido e natural.

Atualmente, a ferramenta oferece suporte para intera√ß√£o com as seguintes LLMs na segunda camada:
* Google Gemini 1.5 Flash
* OpenAI GPT-4o Mini
* Anthropic Claude 3 Haiku
* Um modelo local via Ollama (configurado para `gemma3:4b`)

Uma funcionalidade de calculadora de tokens tamb√©m foi incorporada para auxiliar na estimativa do tamanho do texto extra√≠do de PDFs.

## A T√©cnica de Anonimiza√ß√£o em Duas Camadas

A metodologia central do Anonimizador Veredict baseia-se em duas etapas distintas para garantir tanto a seguran√ßa da anonimiza√ß√£o quanto a qualidade do texto final:

### Camada 1: Anonimiza√ß√£o Estruturada e Controlada (Presidio + spaCy)
Nesta fase crucial, o texto original √© submetido a um processo de anonimiza√ß√£o robusto e n√£o generativo:
* **Detec√ß√£o de PII:** Utiliza o Presidio Analyzer, apoiado pelo modelo de linguagem `pt_core_news_lg` do spaCy. S√£o empregados reconhecedores customizados (baseados em Regex e listas de termos) para identificar uma ampla gama de PIIs, incluindo CPF, OAB, CEP, Nomes (com suporte de uma lista externa customiz√°vel em `sobrenomes_comuns.txt`), entre outros.
* **Preserva√ß√£o Inteligente:** Termos espec√≠ficos como Estados/Capitais (`SAFE_LOCATION`), express√µes de cabe√ßalho jur√≠dico (`LEGAL_HEADER`), estado civil (`ESTADO_CIVIL`) e nomes de organiza√ß√µes conhecidas (`ORGANIZACAO_CONHECIDA`) s√£o identificados e preservados, conforme configurado.
* **Substitui√ß√£o por Tags:** As PIIs detectadas (que n√£o est√£o nas listas de preserva√ß√£o) s√£o substitu√≠das por tags gen√©ricas e claras (ex: `<NOME>`, `<ENDERECO>`, `<CPF>`).
* **Seguran√ßa e Determinismo:** Esta camada opera de forma totalmente determin√≠stica. A aus√™ncia de IA Generativa nesta etapa garante que a identifica√ß√£o e o mascaramento de dados sens√≠veis sejam baseados estritamente nas regras e modelos configurados, eliminando riscos de alucina√ß√µes ou vazamentos de dados durante o processo de anonimiza√ß√£o prim√°ria.

O resultado desta primeira camada √© um texto integralmente anonimizado, com placeholders no lugar dos dados sens√≠veis, pronto para uso seguro.

### Camada 2: Sumariza√ß√£o Jur√≠dica Avan√ßada com IA Generativa (Opcional e Flex√≠vel)
Ap√≥s a anonimiza√ß√£o pela primeira camada, o usu√°rio tem a op√ß√£o de processar o texto (que agora cont√©m as tags) com uma LLM de sua escolha:
* **Sele√ß√£o de LLMs:** A interface permite ao usu√°rio escolher entre:
    * Google Gemini 1.5 Flash (`gemini-1.5-flash-latest`)
    * OpenAI GPT-4o Mini (`gpt-4o-mini`)
    * Anthropic Claude 3 Haiku (`claude-3-haiku-20240307`)
    * LLM local via Ollama (configurado para `gemma3:4b` ou outro modelo dispon√≠vel localmente)
* **Objetivo da LLM (Conforme Prompt Detalhado):** A LLM √© instru√≠da a "Elaborar um resumo detalhado e minucioso do documento jur√≠dico fornecido, destacando todos os aspectos factuais e processuais relevantes (...) omitindo rigorosamente quaisquer informa√ß√µes pessoais ou sens√≠veis que tenham sido substitu√≠das por tags de anonimiza√ß√£o (...) mantendo apenas os dados juridicamente essenciais para compreens√£o do caso (...) estruturando o resumo em linguagem jur√≠dica precisa e objetiva." A LLM tamb√©m √© instru√≠da a n√£o repetir as tags e a n√£o incluir frases introdut√≥rias ou de encerramento gen√©ricas.
* **Output Refinado:** O resultado √© um texto resumido, com linguagem jur√≠dica, que busca fluidez e clareza, ideal para contextos onde a leitura direta das tags de anonimiza√ß√£o seria menos pr√°tica.

Esta abordagem dual permite um controle robusto sobre a privacidade dos dados, ao mesmo tempo que oferece o poder da IA Generativa para refinar e resumir o conte√∫do de forma inteligente.

## Funcionalidades Principais

* Anonimiza√ß√£o precisa e configur√°vel de uma vasta gama de PIIs.
* Preserva√ß√£o de termos importantes atrav√©s de listas de permiss√£o.
* Reconhecimento de nomes aprimorado por lista externa de sobrenomes.
* Suporte para anonimiza√ß√£o de texto extra√≠do de arquivos PDF.
* Op√ß√£o para anonimizar texto colado diretamente na interface.
* **Calculadora de Tokens:** Exibe uma estimativa de tokens (baseada em `tiktoken`) para o texto de PDFs carregados.
* **Sele√ß√£o de M√∫ltiplas LLMs:** Permite ao usu√°rio escolher entre Google Gemini, OpenAI GPT-4o Mini, Anthropic Claude 3 Haiku, ou um modelo Ollama local para a tarefa de sumariza√ß√£o/reescrita.
* Gera√ß√£o de resumos jur√≠dicos fluidos e detalhados a partir do texto anonimizado.
* Interface organizada em abas, com passos claros para o usu√°rio.
* Op√ß√µes para download do texto anonimizado de PDFs em formato `.docx`.
* Bot√µes para copiar os textos anonimizados e os textos reescritos pela IA.

## Tecnologias Utilizadas

* **Python 3.9+**
* **Streamlit:** Para a interface web interativa.
* **Presidio (Analyzer & Anonymizer):** Para a l√≥gica de anonimiza√ß√£o (Camada 1).
* **spaCy (modelo `pt_core_news_lg`):** Para Processamento de Linguagem Natural e NER.
* **APIs de LLM (Camada 2):**
    * `google-generativeai` (para Google Gemini)
    * `openai` (para OpenAI GPT-4o Mini)
    * `anthropic` (para Anthropic Claude 3 Haiku)
    * `requests` (para interagir com a API local do Ollama)
* **Gerenciamento de Configura√ß√£o:**
    * `python-dotenv`: Para carregar chaves API de um arquivo `.env`.
* **Outras Bibliotecas:**
    * `httpx`: Cliente HTTP (usado pela biblioteca `openai`).
    * `tiktoken`: Para estimativa de contagem de tokens (principalmente para modelos OpenAI).
    * `pandas`: Para visualiza√ß√£o de entidades detectadas.
    * `PyMuPDF (fitz)`: Para extra√ß√£o de texto de PDF.
    * `python-docx`: Para cria√ß√£o de arquivos `.docx`.
    * `st-copy-to-clipboard`: Para funcionalidade de c√≥pia.

## Configura√ß√£o do Ambiente Local

Siga os passos abaixo para configurar e executar o projeto na sua m√°quina.

### 1. Clonar o Reposit√≥rio (se aplic√°vel)
   ```bash
   git clone [https://github.com/rgsouza2024/anonimizador_veredict.git](https://github.com/rgsouza2024/anonimizador_veredict.git)
   cd anonimizador_veredict
2. Criar e Ativar um Ambiente Virtual (Recomendado)
Bash

python -m venv .venv
# No Windows (PowerShell):
.\.venv\Scripts\Activate.ps1
# No Windows (CMD):
.\.venv\Scripts\activate.bat
# No macOS/Linux:
# source .venv/bin/activate
3. Instalar Depend√™ncias
Certifique-se de que o arquivo requirements.txt na raiz do projeto cont√©m todas as bibliotecas listadas na se√ß√£o "Tecnologias Utilizadas". Se n√£o, crie ou atualize-o:

Plaintext

streamlit
spacy
presidio-analyzer
presidio-anonymizer
pandas
st-copy-to-clipboard
PyMuPDF
python-docx
python-dotenv
google-generativeai
openai
anthropic
requests
tiktoken
httpx
Em seguida, instale as depend√™ncias:

Bash

pip install -r requirements.txt
4. Baixar o Modelo de Linguagem spaCy
Bash

python -m spacy download pt_core_news_lg
5. Configurar Chaves de API e Ollama
Arquivo .env: Crie um arquivo chamado .env na raiz do projeto (anonimizador_veredict/.env) e adicione suas chaves API:
Snippet de c√≥digo

GOOGLE_API_KEY="sua_chave_api_do_google_aqui"
OPENAI_API_KEY="sua_chave_api_da_openai_aqui"
ANTHROPIC_API_KEY="sua_chave_api_da_anthropic_aqui"
IMPORTANTE: Adicione o arquivo .env ao seu .gitignore para n√£o versionar suas chaves!
Ollama:
Certifique-se de que o Ollama est√° instalado e em execu√ß√£o na sua m√°quina (geralmente em http://localhost:11434).
Baixe o modelo Gemma desejado via terminal. Para o gemma3:4b que voc√™ mencionou (verifique o tag exato no Ollama Hub se este n√£o for o correto):
Bash

ollama pull gemma3:4b
(Substitua gemma3:4b pelo tag exato do modelo Gemma que voc√™ instalou, por exemplo gemma2:9b ou gemma:7b se "gemma3:4b" n√£o for um tag padr√£o reconhecido pelo seu Ollama).
6. Arquivo de Sobrenomes
Crie (ou certifique-se que existe) o arquivo sobrenomes_comuns.txt na raiz do projeto, com um sobrenome por linha, para aprimorar a anonimiza√ß√£o de nomes.

Como Executar a Aplica√ß√£o
Ative seu ambiente virtual.
Navegue at√© a pasta do projeto no seu terminal.
Execute o Streamlit:
Bash

streamlit run anonimizador_veredict.py
A aplica√ß√£o abrir√° automaticamente no seu navegador web padr√£o (geralmente http://localhost:8501).
Como Usar a Ferramenta
A interface da aplica√ß√£o √© dividida em abas para "Anonimizar Arquivo PDF" e "Anonimizar Texto Colado".

Camada 1 - Anonimiza√ß√£o:

Para PDFs: Na aba correspondente, carregue seu arquivo. Uma estimativa de tokens ser√° exibida. Clique em "üîç Anonimizar PDF Carregado".
Para Texto Colado: Na aba correspondente, insira o texto e clique em "‚ú® Anonimizar Texto da √Årea".
O resultado ser√° um texto com PIIs substitu√≠das por tags (ex: <NOME>). Voc√™ pode visualizar o texto original (para PDFs), baixar o texto anonimizado (PDFs) ou copi√°-lo.
Camada 2 - Gera√ß√£o de Resumo Jur√≠dico com IA (Opcional):

Ap√≥s a anonimiza√ß√£o da Camada 1, uma se√ß√£o "Passo 3 (Opcional): Gere um resumo jur√≠dico com IA" aparecer√°.
Escolha a LLM desejada na lista suspensa (Google Gemini, OpenAI GPT-4o Mini, Anthropic Claude Haiku, ou Ollama Local).
Clique no bot√£o "‚ú® Gerar Resumo com [Nome da LLM]".
Aguarde o processamento. O resultado ser√° um resumo jur√≠dico do texto, reescrito para ser fluido e omitindo as informa√ß√µes das tags. Este texto tamb√©m pode ser copiado.
Importante:

Trata-se de ferramenta em desenvolvimento (Vers√£o 1.1 Beta).
A funcionalidade de reescrita com IA requer a chave API correspondente ao servi√ßo em nuvem escolhido, devidamente configurada no arquivo .env. Para Ollama, o servidor local deve estar em execu√ß√£o com o modelo especificado.
Sempre confira o resultado gerado, tanto da anonimiza√ß√£o quanto da reescrita pela IA. A IA, embora poderosa, pode cometer erros ou interpretar instru√ß√µes de maneiras inesperadas.
Autor
Juiz Federal Rodrigo Gon√ßalves de Souza

Licen√ßa
(Considere adicionar uma licen√ßa open-source como MIT ou Apache 2.0 se o reposit√≥rio for p√∫blico e voc√™ desejar incentivar a colabora√ß√£o e o reuso. Caso contr√°rio, pode omitir ou declarar "Todos os direitos reservados".)


**Recomenda√ß√µes para voc√™:**
* **Verifique os Nomes dos Modelos:** Confirme os IDs exatos dos modelos que voc√™ est√° usando (especialmente para "Gemma3 4B" no Ollama e se "Claude 3.5 Haiku" tem um ID diferente de `claude-3-haiku-20240307` que seja o `latest`). Ajuste as constantes `MODELO_...` no script se necess√°rio.
* **Teste Cada LLM:** Certifique-se de que cada op√ß√£o de LLM funciona conforme esperado ap√≥s configurar as respectivas chaves API e o servidor Ollama.
* **Adicione e Commite:** Salve este conte√∫do como `README.md` na raiz do seu projeto, e depois adicione, commite e d√™ push para o seu GitHub para que ele fique atualizado.

Este README agora deve cobrir de forma abrangente o estado atual e as capacidades do seu projeto "Anonimizador Veredict"!