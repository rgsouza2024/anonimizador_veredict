# Nome do arquivo: anonimizador.py
# Vers√£o 0.96 (Beta)

import streamlit as st
import spacy
from presidio_analyzer import AnalyzerEngine, PatternRecognizer
from presidio_analyzer.nlp_engine import SpacyNlpEngine
from presidio_analyzer.pattern import Pattern
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig
import pandas as pd
from st_copy_to_clipboard import st_copy_to_clipboard
import io
import fitz  # PyMuPDF
from docx import Document
import re
import os
from dotenv import load_dotenv
import google.generativeai as genai
from groq import Groq
import openai
import anthropic
import requests 
import json # Embora n√£o usado diretamente no exemplo Ollama, pode ser √∫til para JSON payloads
import tiktoken 

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# --- Constantes ---
NOME_ARQUIVO_SOBRENOMES = "sobrenomes_comuns.txt"
NOME_ARQUIVO_TERMOS_COMUNS = "termos_comuns.txt"
PATH_DA_LOGO = "Logo - AnonimizaJud.png" 
SYSTEM_PROMPT_BASE = "Atue como um assessor jur√≠dico brasileiro especialista em reda√ß√£o jur√≠dica e experi√™ncia no tratamento de documentos anonimizados. Seja descritivo e n√£o fa√ßa ju√≠zo de valor. Responda DIRETAMENTE com a informa√ß√£o solicitada, sem justificativas. Limite-se ao conte√∫do do texto fornecido pelo usu√°rio. N√£o invente, n√£o crie e nem altere informa√ß√µes. Substitua as informa√ß√µes das tags (ex: <NOME> e <ENDERECO>) por textos fluidos e express√µes gen√©ricas, sem utiliza√ß√£o da tags ou de markdown."
PROMPT_INSTRUCAO_LLM_BASE = """Voc√™ receber√° um texto que foi previamente anonimizado. Limite-se ao conte√∫do do texto recebido. Substituindo as informa√ß√µes das tags (ex: <NOME> e <ENDERECO>) por textos fluidos e express√µes gen√©ricas, sem utiliza√ß√£o da tags ou de markdown, fa√ßa um resumo detalhado do texto fornecido. Destaque minuciosamente os fatos, os argumentos jur√≠dicos e os pedidos. Omita informa√ß√µes pessoais ou sens√≠veis por express√µes gen√©ricas. NUNCA use tags de anonimiza√ß√£o. N√£o utilize markdowns nem formata√ß√£o de texto. Traga no output apenas o texto reescrito. Nunca apresente frases introdut√≥rias do tipo 'Aqui est√° a vers√£o reescrita do texto...' ou frases de encerramento do tipo 'A reescrita mant√©m a estrutura formal do documento...'."
"""

# Modelos LLM IDs
MODELO_GEMINI = "gemini-2.0-flash-lite"
MODELO_OPENAI = "gpt-4.1-nano-2025-04-14"
MODELO_CLAUDE = "claude-3-5-haiku-latest"
MODELO_GROQ_LLAMA3_70B = "llama-3.3-70b-versatile"
MODELO_OLLAMA_GEMMA = "gemma3:12b" 
MODELO_OLLAMA_DEEPSEEK = "deepseek-r1"
MODELO_OLLAMA_NEMOTRON = "nemotron-mini"
OLLAMA_BASE_URL = "http://localhost:11434"

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Anonimizador",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Chaves para os widgets e session state ---
VERSION_SUFFIX = "_multillm_v1_1" 
KEY_TEXTO_ORIGINAL_AREA = f"texto_original_input_area{VERSION_SUFFIX}"
KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE = f"texto_anonimizado_output_area_state{VERSION_SUFFIX}"
KEY_PDF_UPLOADER = f"pdf_uploader{VERSION_SUFFIX}"
KEY_BOTAO_ANONIMIZAR_PDF = f"botao_anonimizar_pdf{VERSION_SUFFIX}"
KEY_BOTAO_APAGAR_AREA = f"botao_apagar_area{VERSION_SUFFIX}"
KEY_BOTAO_ANONIMIZAR_AREA = f"botao_anonimizar_area{VERSION_SUFFIX}"
KEY_COPY_BTN_FILE_ANON = f"copy_btn_file_anon{VERSION_SUFFIX}" # Renomeado para clareza
KEY_COPY_BTN_AREA_ANON = f"copy_btn_area_anon{VERSION_SUFFIX}" # Renomeado para clareza
KEY_TEXTO_ORIGINAL_PDF_DISPLAY = f"texto_original_pdf_exp{VERSION_SUFFIX}"
KEY_LLM_CHOICE_PDF = f"llm_choice_pdf{VERSION_SUFFIX}"
KEY_LLM_CHOICE_AREA = f"llm_choice_area{VERSION_SUFFIX}"
KEY_LLM_REWRITE_BTN_PDF = f"llm_rewrite_pdf{VERSION_SUFFIX}"
KEY_LLM_REWRITE_BTN_AREA = f"llm_rewrite_area{VERSION_SUFFIX}"
KEY_LLM_OUTPUT_PDF_STATE = f"llm_output_pdf_state{VERSION_SUFFIX}"
KEY_LLM_OUTPUT_AREA_STATE = f"llm_output_area_state{VERSION_SUFFIX}"
KEY_COPY_LLM_PDF = f"copy_llm_pdf{VERSION_SUFFIX}"
KEY_COPY_LLM_AREA = f"copy_llm_area{VERSION_SUFFIX}"
KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM = f"texto_extraido_pdf_contagem{VERSION_SUFFIX}"
KEY_NUM_TOKENS_PDF_EXTRAIDO = f"num_tokens_pdf_extraido{VERSION_SUFFIX}"

# --- Fun√ß√µes de Callback e Utilit√°rias ---
def callback_apagar_textos_area():
    # Apaga o conte√∫do da √°rea de texto original
    st.session_state[KEY_TEXTO_ORIGINAL_AREA] = ""
    # Reseta o placeholder da √°rea de texto anonimizado
    st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = "O resultado da anonimiza√ß√£o aparecer√° aqui..."
    # Limpa o dataframe de resultados
    if 'resultados_df_area' in st.session_state: # Usando chave sem sufixo como no seu √∫ltimo c√≥digo
        st.session_state.resultados_df_area = pd.DataFrame()
    # Limpa o output da LLM para a √°rea de texto
    if KEY_LLM_OUTPUT_AREA_STATE in st.session_state:
        st.session_state[KEY_LLM_OUTPUT_AREA_STATE] = None
    
    # Limpeza de estados relacionados ao PDF, caso o bot√£o seja considerado "Limpar Tudo"
    # Se for s√≥ para a aba de texto, remova estas linhas.
    if 'nome_arquivo_carregado' in st.session_state:
        st.session_state.nome_arquivo_carregado = None
    if 'texto_anonimizado_arquivo' in st.session_state: 
        st.session_state.texto_anonimizado_arquivo = None
    if KEY_TEXTO_ORIGINAL_PDF_DISPLAY in st.session_state:
        st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = ""
    if KEY_LLM_OUTPUT_PDF_STATE in st.session_state:
        st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None
    if KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM in st.session_state:
        st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM] = ""
    if KEY_NUM_TOKENS_PDF_EXTRAIDO in st.session_state:
        st.session_state[KEY_NUM_TOKENS_PDF_EXTRAIDO] = 0

def carregar_lista_de_arquivo(nome_arquivo):
    lista_itens = []
    caminho_base = os.path.dirname(__file__)
    caminho_arquivo = os.path.join(caminho_base, nome_arquivo)
    try:
        with open(caminho_arquivo, "r", encoding="utf-8") as f:
            for linha in f:
                item = linha.strip()
                if item: lista_itens.append(item)
        if not lista_itens and os.path.exists(caminho_arquivo):
            st.warning(f"O arquivo de lista '{nome_arquivo}' foi encontrado, mas est√° vazio.")
    except FileNotFoundError: st.warning(f"Arquivo de lista '{nome_arquivo}' n√£o encontrado.")
    except Exception as e: st.error(f"Erro ao ler o arquivo '{nome_arquivo}': {e}")
    return lista_itens

# --- Listas Est√°ticas (Completas) ---
LISTA_ESTADOS_CAPITAIS_BR = [
    "Acre", "AC",
    "Alagoas", "AL",
    "Amap√°", "AP",
    "Amazonas", "AM",
    "Bahia", "BA",
    "Cear√°", "CE",
    "Distrito Federal", "DF",
    "Esp√≠rito Santo", "ES",
    "Goi√°s", "GO",
    "Maranh√£o", "MA",
    "Mato Grosso", "MT",
    "Mato Grosso do Sul", "MS",
    "Minas Gerais", "MG",
    "Par√°", "PA",
    "Para√≠ba", "PB",
    "Paran√°", "PR",
    "Pernambuco", "PE",
    "Piau√≠", "PI",
    "Rio de Janeiro", "RJ",
    "Rio Grande do Norte", "RN",
    "Rio Grande do Sul", "RS",
    "Rond√¥nia", "RO",
    "Roraima", "RR",
    "Santa Catarina", "SC",
    "S√£o Paulo", "SP",
    "Sergipe", "SE",
    "Tocantins", "TO",
    "Aracaju",        # Sergipe
    "Bel√©m",          # Par√°
    "Belo Horizonte", # Minas Gerais
    "Boa Vista",      # Roraima
    "Bras√≠lia",       # Distrito Federal
    "Campo Grande",   # Mato Grosso do Sul
    "Cuiab√°",         # Mato Grosso
    "Curitiba",       # Paran√°
    "Florian√≥polis",  # Santa Catarina
    "Fortaleza",      # Cear√°
    "Goi√¢nia",        # Goi√°s
    "Jo√£o Pessoa",    # Para√≠ba
    "Macap√°",         # Amap√°
    "Macei√≥",         # Alagoas
    "Manaus",         # Amazonas
    "Natal",          # Rio Grande do Norte
    "Palmas",         # Tocantins
    "Porto Alegre",   # Rio Grande do Sul
    "Porto Velho",    # Rond√¥nia
    "Recife",         # Pernambuco
    "Rio Branco",     # Acre
    "Salvador",       # Bahia
    "S√£o Lu√≠s",       # Maranh√£o
    "S√£o Paulo",      # (cidade) - mesma situa√ß√£o do Rio de Janeiro.
    "Teresina",       # Piau√≠
    "Vit√≥ria"         # Esp√≠rito Santo
]
TERMOS_CABECALHO_LEGAL_NAO_ANONIMIZAR = [
    "EXMO. SR. DR. JUIZ FEDERAL", "EXMO SR DR JUIZ FEDERAL",
    "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ FEDERAL", "JUIZ FEDERAL",
    "EXMO. SR. DR. JUIZ DE DIREITO", "EXMO SR DR JUIZ DE DIREITO",
    "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ DE DIREITO", "JUIZ DE DIREITO",
    "JUIZADO ESPECIAL FEDERAL", "VARA DA SE√á√ÉO JUDICI√ÅRIA", "SE√á√ÉO JUDICI√ÅRIA", "EXMO.",
    "EXMO", "SR.", "DR.", "Dra.", "DRA.", "EXCELENT√çSSIMO(A) SENHOR(A) DOUTOR(A) JUIZ(A) FEDERAL"
]
LISTA_ESTADO_CIVIL = [
    "casado", "casada", "solteiro", "solteira", "vi√∫vo", "vi√∫va", 
    "divorciado", "divorciada", "separado", "separada", "unido", "unida",
    "companheiro", "companheira", "amasiado", "amasiada", "uni√£o est√°vel",
    "em uni√£o est√°vel"
]
LISTA_ORGANIZACOES_CONHECIDAS = [
    "SIAPE", "FUNASA", "INSS", "IBAMA", "CNPQ", "IBGE", "FIOCRUZ",
    "SERPRO", "DATAPREV", "VALOR", "Justi√ßa", "Justica", "Segredo",
    "Assunto", "Tribunal Regional Federal", "Assuntos", "Vara Federal",
    "Vara", "Justi√ßa Federal", "Federal", "Juizado", "Especial", "Federal",
    "Vara Federal de Juizado Especial C√≠vel", "Turma", "Turma Recursal",
    "SJGO", "SJDF", "SJMA", "SJAC", "SJAL", "SJAP", "SJAM", "SJBA", "SJCE", 
    "SJDF", "SJES", "SJGO", "SJMA", "SJMG", "SJMS", "SJMT", "SJPA", "SJPB", 
    "SJPE", "SJPI", "SJPR", "SJPE", "SJRN", "SJRO", "SJRR", "SJRS", "SJSC",
    "SJSE", "SJSP", "SJTO" 
]
LISTA_SOBRENOMES_FREQUENTES_BR = carregar_lista_de_arquivo(NOME_ARQUIVO_SOBRENOMES)
LISTA_TERMOS_COMUNS = carregar_lista_de_arquivo(NOME_ARQUIVO_TERMOS_COMUNS)

# --- Configura√ß√£o e Inicializa√ß√£o do Presidio ---
@st.cache_resource
def carregar_analyzer_engine(termos_safe_location, 
                             termos_legal_header, 
                             lista_sobrenomes,
                             termos_estado_civil, 
                             termos_organizacoes_conhecidas, 
                             termos_comuns_a_manter):
    try:
        try:
            spacy.load('pt_core_news_lg')
        except OSError:
            st.error("Modelo spaCy 'pt_core_news_lg' n√£o encontrado. Instale com: python -m spacy download pt_core_news_lg")
            return None
        
        spacy_engine_obj = SpacyNlpEngine(models=[{'lang_code': 'pt', 'model_name': 'pt_core_news_lg'}])
        analyzer = AnalyzerEngine(nlp_engine=spacy_engine_obj, supported_languages=["pt"], default_score_threshold=0.4)
        
        # Reconhecedor para Locais Seguros (Estados e Capitais)
        if termos_safe_location: # Adicionado check para lista n√£o vazia
            recognizer_safe_location = PatternRecognizer(
                supported_entity="SAFE_LOCATION", 
                name="SafeLocationRecognizer", 
                deny_list=termos_safe_location, 
                supported_language="pt", 
                deny_list_score=0.99
            )
            analyzer.registry.add_recognizer(recognizer_safe_location)
        
        # Reconhecedor para Cabe√ßalhos Legais
        if termos_legal_header: # Adicionado check para lista n√£o vazia
            recognizer_legal_header = PatternRecognizer(
                supported_entity="LEGAL_HEADER", 
                name="LegalHeaderRecognizer", 
                deny_list=termos_legal_header, 
                supported_language="pt", 
                deny_list_score=0.99
            )
            analyzer.registry.add_recognizer(recognizer_legal_header)
        
        # Reconhecedor para CPF
        cpf_pattern = Pattern(name="CpfRegexPattern", regex=r"\b\d{3}\.\d{3}\.\d{3}-\d{2}\b", score=0.85)
        cpf_recognizer = PatternRecognizer(
            supported_entity="CPF", 
            name="CustomCpfRecognizer", 
            patterns=[cpf_pattern], 
            supported_language="pt"
        )
        analyzer.registry.add_recognizer(cpf_recognizer)
        
        # Reconhecedor para OAB_NUMBER
        oab_pattern = Pattern(name="OabRegexPattern", regex=r"\b(?:OAB\s+)?\d{1,6}(?:\.\d{3})?\s*\/\s*[A-Z]{2}\b", score=0.85)
        oab_recognizer = PatternRecognizer(
            supported_entity="OAB_NUMBER", 
            name="CustomOabRecognizer", 
            patterns=[oab_pattern], 
            supported_language="pt"
        )
        analyzer.registry.add_recognizer(oab_recognizer)

        # Reconhecedor para CEP_NUMBER
        cep_pattern = Pattern(name="CepPattern", regex=r"\b(\d{5}-?\d{3}|\d{2}\.\d{3}-?\d{3})\b", score=0.80) 
        cep_recognizer = PatternRecognizer(
            supported_entity="CEP_NUMBER", 
            name="CustomCepRecognizer", 
            patterns=[cep_pattern], 
            supported_language="pt"
        )
        analyzer.registry.add_recognizer(cep_recognizer)

        # Reconhecedor para ESTADO_CIVIL
        if termos_estado_civil:
            estado_civil_patterns = [Pattern(name=f"estado_civil_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in termos_estado_civil]
            ec_recognizer = PatternRecognizer(
                supported_entity="ESTADO_CIVIL", 
                name="EstadoCivilRecognizer", 
                patterns=estado_civil_patterns, 
                supported_language="pt"
            )
            analyzer.registry.add_recognizer(ec_recognizer)

        # Reconhecedor para ORGANIZACOES_CONHECIDAS
        if termos_organizacoes_conhecidas:
            org_patterns = [Pattern(name=f"org_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in termos_organizacoes_conhecidas]
            org_recognizer = PatternRecognizer(
                supported_entity="ORGANIZACAO_CONHECIDA", 
                name="OrganizacaoConhecidaRecognizer", 
                patterns=org_patterns, 
                supported_language="pt"
            )
            analyzer.registry.add_recognizer(org_recognizer)
        
        # Reconhecedor para Sobrenomes Frequentes (da lista externa)
        if lista_sobrenomes:
            surnames_patterns = [Pattern(name=f"surname_{s.lower().replace(' ', '_')}", regex=rf"(?i)\b{re.escape(s)}\b", score=0.97) for s in lista_sobrenomes]
            surnames_recognizer = PatternRecognizer(
                supported_entity="PERSON", 
                name="BrazilianCommonSurnamesRecognizer", 
                patterns=surnames_patterns, 
                supported_language="pt"
            )
            analyzer.registry.add_recognizer(surnames_recognizer)
        
        # --- Reconhecedor para IDs de Documento/Processo/Benef√≠cio (REFINADO) ---
        id_documento_patterns = [
            # Para NB XXXXXXXXX-X ou XXX.XXX.XXX-X
            Pattern(name="numero_beneficio_nb_formatado", regex=r"\bNB\s*\d{1,3}(\.?\d{3}){2}-[\dX]\b", score=0.98),
            # Para IDs PJe longos e puramente num√©ricos (ex: ID do Documento, N√∫mero do Documento)
            # Este regex pega sequ√™ncias de 10 a 25 d√≠gitos. Ajuste os limites se necess√°rio.
            Pattern(name="id_numerico_longo_pje", regex=r"\b\d{10,25}\b", score=0.97), 
            # Para IDs que come√ßam com "ID " seguido de n√∫meros (como no seu exemplo ID 2028869157 do teste anterior)
            Pattern(name="id_prefixo_numerico", regex=r"\bID\s*\d{8,12}\b", score=0.97),
            # Para RG no formato XXXXXXX-X ou X.XXX.XXX-X, com varia√ß√µes de "¬™ VIA" e √≥rg√£o emissor
            Pattern(name="numero_rg_completo", regex=r"\bRG\s*(?:n¬∫|n\.)?\s*[\d.X-]+(?:-\d¬™\s*VIA)?\s*-\s*[A-Z]{2,3}\/[A-Z]{2}\b", score=0.98),
            Pattern(name="numero_rg_simples", regex=r"\bRG\s*(?:n¬∫|n\.)?\s*[\d.X-]+\b", score=0.97), # RG mais simples sem √≥rg√£o emissor
            # N√∫mero de processo CNJ (manter score alto para prote√ß√£o)
            Pattern(name="numero_processo_cnj", regex=r"\b\d{7}-\d{2}\.\d{4}\.\d\.\d{2}\.\d{4}\b", score=0.95),
            # Para RNM (Registro Nacional Migrat√≥rio)
            Pattern(name="numero_rnm", regex=r"\bRNM\s*(?:n¬∫|n\.)?\s*[A-Z0-9]{7,15}\b", score=0.98), # Ex: RNM n¬∫ F5725832
            # Para CRM (Conselho Regional de Medicina)
            Pattern(name="numero_crm", regex=r"\bCRM\s*[A-Z]{2}\s*-\s*\d{1,6}\b", score=0.98) # Ex: CRM RR-2498
        ]
        id_documento_recognizer = PatternRecognizer(
            supported_entity="ID_DOCUMENTO", 
            name="IdDocumentoRecognizer",
            patterns=id_documento_patterns,
            supported_language="pt"
            # context = ["NB", "ID", "CRM", "RNM", "RG", "Processo"] # Contexto pode ajudar a aumentar a precis√£o
        )
        analyzer.registry.add_recognizer(id_documento_recognizer)
        # --- FIM DO NOVO RECONHECEDOR ---
        
        return analyzer
    except Exception as e:
        st.error(f"Erro cr√≠tico ao carregar o AnalyzerEngine: {e}.")
        return None

@st.cache_resource
def carregar_anonymizer_engine():
    try:
        engine = AnonymizerEngine()
        return engine
    except Exception as e:
        st.error(f"Erro cr√≠tico ao carregar o AnonymizerEngine: {e}.")
        return None

def obter_operadores_anonimizacao():
    return {
        "DEFAULT": OperatorConfig("keep"),
        "PERSON": OperatorConfig("replace", {"new_value": "<NOME>"}),
        "LOCATION": OperatorConfig("replace", {"new_value": "<ENDERECO>"}),
        "EMAIL_ADDRESS": OperatorConfig("replace", {"new_value": "<EMAIL>"}),
        "PHONE_NUMBER": OperatorConfig("mask", {"type": "mask", "masking_char": "*", "chars_to_mask": 4, "from_end": True}),
        "CPF": OperatorConfig("replace", {"new_value": "<CPF>"}),
        "DATE_TIME": OperatorConfig("keep"), 
        "OAB_NUMBER": OperatorConfig("replace", {"new_value": "<OAB>"}),
        "CEP_NUMBER": OperatorConfig("replace", {"new_value": "<CEP>"}),
        "ESTADO_CIVIL": OperatorConfig("keep"),
        "ORGANIZACAO_CONHECIDA": OperatorConfig("keep"),
        "ID_DOCUMENTO": OperatorConfig("keep"), 
        "LEGAL_OR_COMMON_TERM": OperatorConfig("keep")
    }

analyzer_engine = carregar_analyzer_engine(
    LISTA_ESTADOS_CAPITAIS_BR,              # para termos_safe_location
    TERMOS_CABECALHO_LEGAL_NAO_ANONIMIZAR,  # para termos_legal_header
    LISTA_SOBRENOMES_FREQUENTES_BR,         # para lista_sobrenomes
    LISTA_ESTADO_CIVIL,                     # para termos_estado_civil (ESTAVA FALTANDO)
    LISTA_ORGANIZACOES_CONHECIDAS,           # para termos_organizacoes_conhecidas (ESTAVA FALTANDO)
    LISTA_TERMOS_COMUNS
)
anonymizer_engine = carregar_anonymizer_engine()
operadores = obter_operadores_anonimizacao()

def extrair_texto_de_pdf(arquivo_pdf_bytes_io):
    texto_completo = ""
    try:
        documento_pdf = fitz.open(stream=arquivo_pdf_bytes_io, filetype="pdf")
        for pagina in documento_pdf: texto_completo += pagina.get_text()
        documento_pdf.close()
    except Exception as e: st.error(f"Erro ao extrair texto do PDF: {e}"); return None
    return texto_completo

def criar_docx_bytes(texto_anonimizado):
    documento = Document(); documento.add_paragraph(texto_anonimizado)
    bio = io.BytesIO(); documento.save(bio); bio.seek(0)
    return bio.getvalue()

def contar_tokens_para_estimativa(texto: str, llm_provider: str = "openai") -> int:
    if not texto: return 0
    try:
        # Para OpenAI, Anthropic (Claude 2 e anteriores), e uma estimativa para Gemini
        if llm_provider in ["openai", "claude", "gemini_estimate"]: 
            encoding = tiktoken.get_encoding("cl100k_base")
        elif llm_provider == "ollama": 
            return len(texto.split()) # Estimativa grosseira para Ollama/Gemma
        else: 
            encoding = tiktoken.encoding_for_model("gpt-4.1-nano") 
    except KeyError:
        try: encoding = tiktoken.get_encoding("cl100k_base")
        except: return len(texto.split()) 
    except Exception: return len(texto.split())
    return len(encoding.encode(texto))
# --- Fun√ß√µes de Carregamento de Chave API ---
def carregar_chave_api(env_var_name: str, secrets_key_name: str, servico_nome_exibicao: str) -> str | None:
    """Carrega uma chave API da vari√°vel de ambiente ou dos secrets do Streamlit."""
    api_key = os.getenv(env_var_name) 
    if not api_key: 
        try:
            if hasattr(st, 'secrets') and st.secrets.get(secrets_key_name):
                api_key = st.secrets[secrets_key_name]
        except FileNotFoundError: 
            # Isso √© esperado se st.secrets for acessado localmente sem um arquivo secrets.toml
            pass 
        except Exception as e: 
            st.warning(f"Problema ao tentar acessar st.secrets para {servico_nome_exibicao}: {e}")
    
    if not api_key:
        st.error(f"Chave API para {servico_nome_exibicao} n√£o configurada. "
                 f"Defina a vari√°vel de ambiente {env_var_name} no seu arquivo .env (localmente) "
                 f"ou configure {secrets_key_name} em 'Secrets' (para deploy no Streamlit Cloud).")
        return None
    return api_key

# --- Fun√ß√µes de Chamada das LLMs ---

def reescrever_texto_com_openai(texto_anonimizado: str, system_prompt: str, user_prompt_instruction: str, api_key: str) -> str | None:
    """Chama a API da OpenAI para reescrever/resumir o texto."""
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning("OpenAI: N√£o h√° texto anonimizado para reescrever.")
        return None
    try:
        meu_http_client = httpx.Client() # Para evitar problemas com proxies
        client = openai.OpenAI(api_key=api_key, http_client=meu_http_client)
        
        response = client.chat.completions.create(
            model=MODELO_OPENAI, # ex: "gpt-4.1-nano"
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"{user_prompt_instruction}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"}
            ],
            temperature=0.3, 
            max_tokens=32768 # Limite para gpt-4.1-nano, ajuste se necess√°rio
        )
        if response.choices and response.choices[0].message and response.choices[0].message.content:
            return response.choices[0].message.content.strip()
        else:
            st.error("A LLM (OpenAI) n√£o retornou uma resposta de conte√∫do v√°lida.")
            return None
    except openai.AuthenticationError: st.error("Erro de autentica√ß√£o com a API da OpenAI. Verifique sua chave API.")
    except openai.RateLimitError as e: st.error(f"Limite de requisi√ß√µes da API da OpenAI atingido: {e}")
    except openai.APIConnectionError as e: st.error(f"Erro de conex√£o com a API da OpenAI: {e}")
    except openai.APIError as e: st.error(f"Erro na API da OpenAI: {e}")
    except Exception as e: st.error(f"Erro inesperado com OpenAI: {type(e).__name__} - {e}"); return None
    return None # Garantir retorno em todos os caminhos

def reescrever_texto_com_claude(texto_anonimizado: str, system_prompt: str, user_prompt_instruction: str, api_key: str) -> str | None:
    """Chama a API da Anthropic (Claude) para reescrever/resumir o texto."""
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning("Claude: N√£o h√° texto anonimizado para reescrever.")
        return None
    try:
        client = anthropic.Anthropic(api_key=api_key)
        response = client.messages.create(
            model=MODELO_CLAUDE, # ex: "claude-3-haiku-20240307"
            max_tokens=8192, # Limite generoso para Haiku
            temperature=0.3,
            system=system_prompt, # Claude usa o par√¢metro 'system'
            messages=[
                {"role": "user", "content": f"{user_prompt_instruction}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"}
            ]
        )
        texto_final_reescrito = "".join([block.text for block in response.content if block.type == 'text'])
        return texto_final_reescrito.strip() if texto_final_reescrito else None
    except anthropic.AuthenticationError: st.error("Erro de autentica√ß√£o com a API da Anthropic. Verifique sua chave API.")
    except anthropic.RateLimitError as e: st.error(f"Limite de requisi√ß√µes da API da Anthropic atingido: {e}")
    except anthropic.APIConnectionError as e: st.error(f"Erro de conex√£o com a API da Anthropic: {e}")
    except anthropic.APIError as e: st.error(f"Erro na API da Anthropic: {e}")
    except Exception as e: st.error(f"Erro inesperado com Anthropic Claude: {type(e).__name__} - {e}"); return None
    return None # Garantir retorno

def reescrever_texto_com_gemini(texto_anonimizado: str, system_prompt: str, user_prompt_instruction: str, api_key: str) -> str | None:
    """Chama a API do Google Gemini para reescrever/resumir o texto."""
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning("Gemini: N√£o h√° texto anonimizado para reescrever.")
        return None
    try:
        genai.configure(api_key=api_key)
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=8192, # Limite para Gemini Flash, ajuste se necess√°rio
            temperature=0.3
        )
        safety_settings = [ # Configura√ß√µes de seguran√ßa mais permissivas para teste
            {"category": f"HARM_CATEGORY_{cat}", "threshold": "BLOCK_NONE"} 
            for cat in ["HARASSMENT", "HATE_SPEECH", "SEXUALLY_EXPLICIT", "DANGEROUS_CONTENT"]
        ]
        model = genai.GenerativeModel(
            model_name=MODELO_GEMINI, # ex: "gemini-1.5-flash-latest"
            system_instruction=system_prompt, # Gemini suporta system_instruction
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        prompt_para_gemini = f"{user_prompt_instruction}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"
        response = model.generate_content(prompt_para_gemini)
        
        # Tratamento da resposta do Gemini (pode ser response.text ou response.parts)
        texto_final_reescrito = ""
        if hasattr(response, 'text') and response.text:
            texto_final_reescrito = response.text
        elif response.parts:
            for part in response.parts:
                if hasattr(part, 'text'):
                    texto_final_reescrito += part.text
        
        if texto_final_reescrito:
            return texto_final_reescrito.strip()
        else:
            # Verifica se o prompt foi bloqueado
            if hasattr(response, 'prompt_feedback') and response.prompt_feedback and response.prompt_feedback.block_reason:
                st.error(f"O prompt para Gemini foi bloqueado devido a: {response.prompt_feedback.block_reason.name}")
                if response.prompt_feedback.safety_ratings:
                    st.warning("Classifica√ß√µes de seguran√ßa do prompt:")
                    for rating in response.prompt_feedback.safety_ratings:
                        st.warning(f"  - Categoria: {rating.category.name}, Probabilidade: {rating.probability.name}")
            else:
                st.error("A LLM (Gemini) n√£o retornou uma resposta de conte√∫do v√°lida ou o prompt foi bloqueado sem detalhes.")
            return None

    except ValueError as ve:
        if hasattr(ve, 'args') and ve.args and ("API Key not valid" in str(ve.args[0]) or "API_KEY_INVALID" in str(ve.args[0])):
             st.error(f"Erro de autentica√ß√£o com a API do Google Gemini. Verifique sua chave API: {ve}")
        elif hasattr(ve, 'args') and ve.args and "prompt was blocked" in str(ve.args[0]).lower(): # Outra forma de prompt bloqueado
            st.error(f"O prompt foi bloqueado pela IA do Google (ValueError). Detalhe: {ve}")
        else:
            st.error(f"Ocorreu um erro de valor ao processar com a LLM (Gemini): {ve}")
    except Exception as e: 
        st.error(f"Erro inesperado com Google Gemini: {type(e).__name__} - {e}")
    return None

def reescrever_texto_com_groq(texto_anonimizado: str, system_prompt: str, user_prompt_instruction: str, api_key: str) -> str | None:
    """Chama a API da Groq para reescrever/resumir o texto com Llama 3 70B."""
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning(f"Groq ({MODELO_GROQ_LLAMA3_70B}): N√£o h√° texto anonimizado para reescrever.")
        return None
    try:
        client = Groq(api_key=api_key)
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"{user_prompt_instruction}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"}
        ]

        chat_completion = client.chat.completions.create(
            messages=messages,
            model=MODELO_GROQ_LLAMA3_70B,
            temperature=0.3,
            max_tokens=32768, 
            # Outros par√¢metros como top_p, stream podem ser adicionados se necess√°rio
        )
        
        if chat_completion.choices and chat_completion.choices[0].message and chat_completion.choices[0].message.content:
            return chat_completion.choices[0].message.content.strip()
        else:
            st.error(f"A LLM (Groq - {MODELO_GROQ_LLAMA3_70B}) n√£o retornou uma resposta de conte√∫do v√°lida.")
            return None
    except Exception as e: 
        # A biblioteca groq pode ter exce√ß√µes espec√≠ficas (ex: groq.APIError)
        # Capturar gen√©rico por enquanto, mas pode ser refinado.
        if "API key" in str(e).lower() or "authentication" in str(e).lower():
            st.error(f"Erro de autentica√ß√£o com a API da Groq. Verifique sua GROQ_API_KEY: {e}")
        else:
            st.error(f"Erro com Groq ({MODELO_GROQ_LLAMA3_70B}): {type(e).__name__} - {e}")
        return None

def reescrever_texto_com_ollama(texto_anonimizado: str, system_prompt: str, user_prompt_instruction: str, model_name: str = MODELO_OLLAMA_GEMMA) -> str | None:
    """Chama a API do Ollama local para reescrever/resumir o texto."""
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning(f"Ollama ({model_name}): N√£o h√° texto anonimizado para reescrever.")
        return None
    
    # Tenta incluir system prompt se o modelo/endpoint Ollama suportar, sen√£o concatena ao prompt principal.
    # A API /api/generate do Ollama aceita um campo "system".
    prompt_para_ollama = f"{user_prompt_instruction}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"
    
    payload = {
        "model": model_name,
        "system": system_prompt, 
        "prompt": prompt_para_ollama,
        "stream": False,
        "options": {
            "temperature": 0.3, 
            "num_predict": 32768 # Limite de tokens de sa√≠da para Ollama, ajuste se necess√°rio
        }
    }
    try:
        response = requests.post(f"{OLLAMA_BASE_URL}/api/generate", json=payload, timeout=180) # Timeout aumentado
        response.raise_for_status() # Levanta erro para status HTTP ruins (4xx ou 5xx)
        response_data = response.json()
        
        if "response" in response_data and response_data["response"]:
            return response_data["response"].strip()
        elif "error" in response_data:
            st.error(f"Erro da API Ollama ({model_name}): {response_data['error']}")
            return None
        else:
            st.error(f"A LLM (Ollama - {model_name}) n√£o retornou uma resposta de conte√∫do v√°lida ou a resposta estava vazia.")
            return None
            
    except requests.exceptions.ConnectionError:
        st.error(f"Ollama ({model_name}) n√£o est√° acess√≠vel em {OLLAMA_BASE_URL}. Verifique se o Ollama est√° em execu√ß√£o e o modelo '{model_name}' foi baixado (ex: `ollama pull {model_name}`).")
    except requests.exceptions.Timeout:
        st.error(f"A requisi√ß√£o para o Ollama ({model_name}) demorou muito (timeout). O servidor pode estar sobrecarregado.")
    except requests.exceptions.HTTPError as http_err:
        st.error(f"Erro HTTP ao chamar Ollama ({model_name}): {http_err}. Detalhes: {response.text}")
    except Exception as e:
        st.error(f"Erro inesperado com Ollama ({model_name}): {type(e).__name__} - {e}")
    return None

# --- Dicion√°rio de Configura√ß√µes das LLMs ---
LLM_CONFIGS = {
    "Google Gemini 2.0 Flash": {
        "id": "gemini", "model_api_name": MODELO_GEMINI, 
        "key_loader_function": lambda: carregar_chave_api("GOOGLE_API_KEY", "GOOGLE_API_KEY", "Google Gemini"),
        "rewrite_function": reescrever_texto_com_gemini,
        "token_estimator_model": "gemini_estimate" # Flag para contar_tokens_para_estimativa
    },
    "OpenAI GPT-4.1 nano": {
        "id": "openai", "model_api_name": MODELO_OPENAI,
        "key_loader_function": lambda: carregar_chave_api("OPENAI_API_KEY", "OPENAI_API_KEY", "OpenAI"),
        "rewrite_function": reescrever_texto_com_openai,
        "token_estimator_model": MODELO_OPENAI
    },
    "Anthropic Claude 3.5 Haiku": {
        "id": "claude", "model_api_name": MODELO_CLAUDE,
        "key_loader_function": lambda: carregar_chave_api("ANTHROPIC_API_KEY", "ANTHROPIC_API_KEY", "Anthropic Claude"),
        "rewrite_function": reescrever_texto_com_claude,
        "token_estimator_model": "claude" # Flag para contar_tokens_para_estimativa
    },
    "Groq Llama3.3 70B Versatile": { 
        "id": "groq_llama3_3_70b", 
        "model_api_name": MODELO_GROQ_LLAMA3_70B, # Usar√° "llama-3.3-70b-versatile"
        "key_loader_function": lambda: carregar_chave_api("GROQ_API_KEY", "GROQ_API_KEY", "Groq"),
        "rewrite_function": reescrever_texto_com_groq,
        "token_estimator_model": "openai" 
    },    
    f"LLM Local GEMMA ({MODELO_OLLAMA_GEMMA})": {
        "id": "ollama", "model_api_name": MODELO_OLLAMA_GEMMA,
        "key_loader_function": lambda: True, 
        "rewrite_function": lambda txt, sys_p, usr_p, api_key_placeholder: reescrever_texto_com_ollama(txt, sys_p, usr_p, MODELO_OLLAMA_GEMMA),
        "token_estimator_model": "ollama"
    },        
    f"LLM Local DEEPSEEK ({MODELO_OLLAMA_DEEPSEEK})": { # <<< NOVA ENTRADA PARA DEEPSEEK
       "id": "ollama_deepseek", # ID interno diferente
       "model_api_name": MODELO_OLLAMA_DEEPSEEK, 
       "key_loader_function": lambda: True, 
       "rewrite_function": lambda txt, sys_p, usr_p, api_key_placeholder: reescrever_texto_com_ollama(txt, sys_p, usr_p, MODELO_OLLAMA_DEEPSEEK),
       "token_estimator_model": "ollama" 
    },
    f"LLM Local NVIDIA NEMOTRON ({MODELO_OLLAMA_NEMOTRON})": {
        "id": "ollama_nemotron", # ID interno √∫nico
        "model_api_name": MODELO_OLLAMA_NEMOTRON, 
        "key_loader_function": lambda: True, 
        "rewrite_function": lambda txt, sys_p, usr_p, api_key_placeholder: reescrever_texto_com_ollama(txt, sys_p, usr_p, MODELO_OLLAMA_NEMOTRON),
        "token_estimator_model": "ollama" 
    }
}
# --- Interface Streamlit Principal ---
st.markdown("<style>div.block-container{padding-top:1rem !important;}</style>", unsafe_allow_html=True)
cols_logo = st.columns([2, 3, 2]) 
with cols_logo[1]: 
    try:
        st.image(PATH_DA_LOGO, width=600) 
    except FileNotFoundError:
        st.error(f"Logo '{PATH_DA_LOGO}' n√£o encontrada.")
    except Exception as e:
        st.warning(f"Logo n√£o p√¥de ser carregada: {e}")
st.divider()
st.markdown("<h3 style='text-align: center;'>Bem-vindo ao Anonimizador!</h3>", unsafe_allow_html=True)
st.caption("Proteja informa√ß√µes sens√≠veis em seus documentos, com a op√ß√£o de gerar um resumo jur√≠dico inteligente do conte√∫do anonimizado. Escolha uma das op√ß√µes abaixo para come√ßar.")
st.markdown("---")

tab_pdf, tab_texto = st.tabs(["üóÇÔ∏è Anonimizar Arquivo PDF", "‚å®Ô∏è Anonimizar Texto Colado"])

# Inicializa√ß√£o de estados para garantir que todas as chaves existem
st.session_state.setdefault(KEY_LLM_OUTPUT_PDF_STATE, None)
st.session_state.setdefault(KEY_LLM_OUTPUT_AREA_STATE, None)
st.session_state.setdefault('texto_anonimizado_arquivo'+VERSION_SUFFIX, None)
st.session_state.setdefault(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE, "O resultado da anonimiza√ß√£o aparecer√° aqui...")
st.session_state.setdefault(KEY_TEXTO_ORIGINAL_PDF_DISPLAY, "")
st.session_state.setdefault(KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM, "")
st.session_state.setdefault(KEY_NUM_TOKENS_PDF_EXTRAIDO, 0)
st.session_state.setdefault('nome_arquivo_carregado'+VERSION_SUFFIX, None)
st.session_state.setdefault('resultados_df_area'+VERSION_SUFFIX, pd.DataFrame()) # Chave espec√≠fica para df da √°rea de texto
st.session_state.setdefault(KEY_TEXTO_ORIGINAL_AREA, (
    "EXMO. SR. DR. JUIZ FEDERAL DA ____¬™ VARA DA SE√á√ÉO JUDICI√ÅRIA DE S√ÉO LU√çS ‚Äì MA ‚Äì JUIZADO ESPECIAL FEDERAL.\n\n"  # Linha em branco adicionada
    "TRAMITA√á√ÉO PRIORIT√ÅRIA ‚Äì AUTOR IDOSO ‚Äì ART.1.048, I DO CPC\n\n"  # Linha em branco adicionada
    "JOS√â RIBAMAR SILVA, brasileiro, casado, servidor p√∫blico federal, matr√≠cula SIAPE n¬∞ 496750, portador da Carteira de Identidade n¬∫ 19673822002-1 SSP-MA e CPF n¬∫ 047.017.123-53, residente e domiciliado na Rua dos Girassois, n¬∫ 13, Pedreiras-MA, CEP: 65725-000. \n\n"  # Linha em branco adicionada
    "LEANDRO REIS VIEIRA XAVIER, brasileiro, casado, servidor p√∫blico federal, matr√≠cula SIAPE n¬∞ 496760, portador da Carteira de Identidade n¬∫ 048758962013-3 SSP-MA e CPF n¬∫ 074.816.243-72, residente e domiciliado na Rua Getulio Vargas, n¬∫ 151, Goiabal, Pedreiras-MA, CEP: 65725-000. \n\n"  # Linha em branco adicionada
    "JO√ÉO FERREIRA SANTOS CORDEIRO, brasileiro, casado, servidor p√∫blico federal, matr√≠cula SIAPE n¬∞ 519473, portador da Carteira de Identidade n¬∫ 050513672013-2 SSP-MA e CPF n¬∫ 251.195.803-87, residente e domiciliado na Travessa Carlos Martins, n¬∫ 22, Seringal, Pedreiras-MA, CEP: 65725-000. \n\n"  # Linha em branco adicionada
    "PEDRO DA SILVA MARTINS OLIVEIRA, brasileiro, casado, servidor p√∫blico federal, matr√≠cula SIAPE n¬∞ 497220, portador da Carteira de Identidade n¬∫ 267317 SSP-MA e CPF n¬∫ 047.003.093-34, residente e domiciliado na Rua Jos√© Sarney, n¬∫ 104, Nova Pedreiras, Pedreiras-MA, CEP: 65725-000. \n\n"  # Linha em branco adicionada
    "MANOEL DE JESUS COLEHO CUTRIM, brasileiro, casado, servidor p√∫blico federal, matr√≠cula SIAPE n¬∫ 496774, portador da Carteira de Identidade n¬∫ 054691322014-7 SSP-MA e CPF n¬∫ 044.646.803-72, residente e domiciliado na Rua Tuiuti, n¬∫ 26, Vila do Bec, Z√© Doca-MA, CEP: 65365-000, por meio de seu advogado, ao fim assinado, este com escrit√≥rio profissional na Avenida do Vale, quadra 22, n¬∫ 10, Renascen√ßa II, S√£o Lu√≠s/MA e endere√ßo eletr√¥nico escritorio@mnz.adv.br, onde recebe as notifica√ß√µes de praxe e estilo, ao fim assinado (procura√ß√£o em anexo), propor a presente: \n\n"  # Linha em branco adicionada
    "A√á√ÉO ORDIN√ÅRIA SOB O RITO DA LEI N¬∫ 10.259/2001 \n\n"  # Linha em branco adicionada
    "Contra a FUNDA√á√ÉO NACIONAL DE SA√öDE ‚Äì FUNASA, pessoa jur√≠dica de Direito P√∫blico, situada na Rua do Apicum, n¬∞ 23, Centro ‚Äì S√£o Lu√≠s- MA, CEP 65025-070, S√£o Lu√≠s/MA, pelos motivos de fato e de direito que passa a expor:"
    # A √∫ltima linha n√£o precisa de um \n\n extra, a menos que voc√™ queira um espa√ßo duplo antes do usu√°rio come√ßar a digitar.
))

# Fun√ß√£o gen√©rica para exibir a se√ß√£o da LLM, agora movida para antes de ser chamada
def exibir_secao_llm(texto_anonimizado_atual, key_llm_output_state, key_llm_choice, key_llm_rewrite_btn, key_copy_llm, tab_id_suffix):
    if texto_anonimizado_atual:
        st.divider()
        st.subheader("Passo 3 (Opcional): Gere um resumo jur√≠dico com IA")
        
        llm_display_names = list(LLM_CONFIGS.keys())
        selectbox_key = f"{key_llm_choice}_{tab_id_suffix}" # Chave √∫nica para selectbox
        
        # Garantir que o selectbox tenha um valor padr√£o no session_state se ainda n√£o tiver
        st.session_state.setdefault(selectbox_key, llm_display_names[0])

        selected_llm_display_name = st.selectbox(
            "Escolha o modelo de IA para o resumo:",
            options=llm_display_names,
            key=selectbox_key # Usa a chave j√° inicializada
        )
        
        config_llm_selecionada = LLM_CONFIGS[selected_llm_display_name]
        
        st.caption(f"Esta etapa usa o modelo {selected_llm_display_name.split('(')[0].strip()} para gerar o resumo.")

        button_key = f"{key_llm_rewrite_btn}_{tab_id_suffix}" # Chave √∫nica para bot√£o
        if st.button(f"‚ú® Gerar Resumo com {selected_llm_display_name.split('(')[0].strip()}", key=button_key, type="primary"):
            api_key_ou_status = config_llm_selecionada["key_loader_function"]()
            
            if api_key_ou_status and texto_anonimizado_atual: 
                with st.spinner(f"{selected_llm_display_name.split('(')[0].strip()} est√° trabalhando na reescrita... Por favor, aguarde."):
                    texto_reescrito = None
                    if config_llm_selecionada["id"] == "ollama": 
                        texto_reescrito = config_llm_selecionada["rewrite_function"](
                            texto_anonimizado_atual, 
                            SYSTEM_PROMPT_BASE, 
                            PROMPT_INSTRUCAO_LLM_BASE,
                            None # api_key n√£o √© passada diretamente, fun√ß√£o lambda lida com model_name
                        )
                    else: 
                         texto_reescrito = config_llm_selecionada["rewrite_function"](
                            texto_anonimizado_atual, 
                            SYSTEM_PROMPT_BASE, 
                            PROMPT_INSTRUCAO_LLM_BASE,
                            api_key_ou_status 
                        )
                    st.session_state[key_llm_output_state] = texto_reescrito
            elif not api_key_ou_status and config_llm_selecionada["id"] != "ollama": pass 
            elif not texto_anonimizado_atual: st.warning("N√£o h√° texto anonimizado para reescrever.")

        texto_llm_atual = st.session_state.get(key_llm_output_state)
        if texto_llm_atual:
            output_area_key = f"llm_output_display_{tab_id_suffix}" # Chave √∫nica para text_area
            copy_button_key = f"{key_copy_llm}_{tab_id_suffix}" # Chave √∫nica para bot√£o de c√≥pia
            st.text_area(f"Resumo Gerado por {selected_llm_display_name.split('(')[0].strip()}:", value=texto_llm_atual, height=300, disabled=True, key=output_area_key)
            st_copy_to_clipboard(texto_llm_atual, f"üìã Copiar Resumo ({selected_llm_display_name.split('(')[0].strip()})", key=copy_button_key)
        elif texto_anonimizado_atual: 
            st.caption("Selecione uma LLM e clique no bot√£o acima para gerar um resumo jur√≠dico do texto anonimizado.")


with tab_pdf:
    st.subheader("Passo 1: Carregue seu documento PDF")
    arquivo_pdf_carregado = st.file_uploader(
        "Selecione o arquivo PDF para anonimiza√ß√£o:", 
        type=["pdf"], 
        key=KEY_PDF_UPLOADER,
        help="Apenas arquivos .pdf s√£o aceitos."
    )
    st.caption("Limite de 200MB por arquivo.")

    if arquivo_pdf_carregado is not None:
        # Verifica se o arquivo mudou para reprocessar a contagem de tokens
        # Usando .get() para nome_arquivo_carregado para evitar KeyError na primeira execu√ß√£o
        if st.session_state.get('nome_arquivo_carregado'+VERSION_SUFFIX) != arquivo_pdf_carregado.name:
            st.session_state['nome_arquivo_carregado'+VERSION_SUFFIX] = arquivo_pdf_carregado.name
            st.session_state['texto_anonimizado_arquivo'+VERSION_SUFFIX] = None 
            st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = "" 
            st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None
            st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM] = ""
            st.session_state[KEY_NUM_TOKENS_PDF_EXTRAIDO] = 0
            
            with st.spinner(f"Lendo o arquivo '{arquivo_pdf_carregado.name}' para calcular tokens..."):
                bytes_do_pdf = arquivo_pdf_carregado.getvalue()
                # Garante que passamos um objeto BytesIO para extrair_texto_de_pdf
                texto_extraido_contagem = extrair_texto_de_pdf(io.BytesIO(bytes_do_pdf))
                st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM] = texto_extraido_contagem if texto_extraido_contagem else ""
                
                if st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM].strip():
                    # Determina qual LLM est√° selecionada para estimar tokens (default para OpenAI se nada selecionado ainda)
                    llm_selecionada_para_token = LLM_CONFIGS.get(st.session_state.get(f"{KEY_LLM_CHOICE_PDF}_pdf", list(LLM_CONFIGS.keys())[0]), {}).get("token_estimator_model", "openai")
                    st.session_state[KEY_NUM_TOKENS_PDF_EXTRAIDO] = contar_tokens_para_estimativa(st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM], llm_provider=llm_selecionada_para_token)
                else:
                    if st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM] is not None: # Evita warning se extra√ß√£o falhou e j√° deu erro
                        st.warning("O PDF carregado parece n√£o conter texto √∫til para contagem de tokens.")
            arquivo_pdf_carregado.seek(0) # Reseta para releitura

        # Exibe a contagem de tokens se dispon√≠vel
        if st.session_state.get(KEY_NUM_TOKENS_PDF_EXTRAIDO, 0) > 0:
            llm_selecionada_display = st.session_state.get(f"{KEY_LLM_CHOICE_PDF}_pdf", list(LLM_CONFIGS.keys())[0]).split('(')[0].strip()
            token_provider_display = "Estimativa Gen√©rica"
            if "OpenAI" in llm_selecionada_display: token_provider_display = "OpenAI"
            elif "Claude" in llm_selecionada_display: token_provider_display = "Anthropic"
            elif "Gemini" in llm_selecionada_display: token_provider_display = "Google"
            elif "Ollama" in llm_selecionada_display: token_provider_display = "Ollama"


            col_info1, col_info2 = st.columns(2)
            with col_info1:
                st.markdown("<strong>Arquivo Carregado:</strong>", unsafe_allow_html=True)
                st.markdown(f"<p style='font-size: 1em; font-weight: normal; margin-top: -10px;'>{st.session_state.get('nome_arquivo_carregado'+VERSION_SUFFIX, 'N/A')}</p>", unsafe_allow_html=True)
            with col_info2:
                st.markdown(f"<strong>Tokens Estimados ({token_provider_display}):</strong>", unsafe_allow_html=True)
                st.markdown(f"<p style='font-size: 1em; font-weight: normal; margin-top: -10px;'>{st.session_state.get(KEY_NUM_TOKENS_PDF_EXTRAIDO, 0)}</p>", unsafe_allow_html=True)
        st.divider()

        st.subheader("Passo 2: Anonimize o conte√∫do do PDF")
        if st.button("üîç Anonimizar PDF Carregado", key=KEY_BOTAO_ANONIMIZAR_PDF, type="primary", 
                      disabled=(not analyzer_engine or not anonymizer_engine or not st.session_state.get(KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM,"").strip())):
            if analyzer_engine and anonymizer_engine:
                texto_para_anonimizar = st.session_state.get(KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM)
                # Tenta re-extrair se o texto n√£o estiver no estado da sess√£o (ex: ap√≥s refresh ou erro)
                if not texto_para_anonimizar or not texto_para_anonimizar.strip():
                    if arquivo_pdf_carregado: # Checa se o uploader ainda tem o arquivo
                        arquivo_pdf_carregado.seek(0) 
                        bytes_pdf = arquivo_pdf_carregado.getvalue()
                        texto_para_anonimizar = extrair_texto_de_pdf(io.BytesIO(bytes_pdf))
                        st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM] = texto_para_anonimizar if texto_para_anonimizar else ""
                    else:
                        st.warning("Por favor, carregue um arquivo PDF novamente.")
                        st.stop() # Interrompe a execu√ß√£o se n√£o h√° arquivo para processar
                
                st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = st.session_state[KEY_TEXTO_EXTRAIDO_PDF_CONTAGEM]
                st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None # Limpa resumo anterior

                if texto_para_anonimizar and texto_para_anonimizar.strip():
                    with st.spinner(f"Anonimizando '{st.session_state.get('nome_arquivo_carregado'+VERSION_SUFFIX)}'..."):
                        entidades_para_analise = list(operadores.keys()) + ["SAFE_LOCATION", "LEGAL_HEADER", "ESTADO_CIVIL", "ORGANIZACAO_CONHECIDA", "ID_DOCUMENTO"]
                        entidades_para_analise = list(set(entidades_para_analise)); 
                        if "DEFAULT" in entidades_para_analise: entidades_para_analise.remove("DEFAULT")
                        resultados_analise_pdf = analyzer_engine.analyze(text=texto_para_anonimizar, language='pt', entities=entidades_para_analise, return_decision_process=False)
                        resultado_anonimizado_pdf_obj = anonymizer_engine.anonymize(text=texto_para_anonimizar, analyzer_results=resultados_analise_pdf, operators=operadores)
                        st.session_state['texto_anonimizado_arquivo'+VERSION_SUFFIX] = resultado_anonimizado_pdf_obj.text
                        st.success(f"Arquivo '{st.session_state.get('nome_arquivo_carregado'+VERSION_SUFFIX)}' anonimizado com sucesso!")
                elif texto_para_anonimizar is not None: 
                    st.warning("O PDF carregado parece n√£o conter texto √∫til para anonimiza√ß√£o.")
                    st.session_state['texto_anonimizado_arquivo'+VERSION_SUFFIX] = None
                else: # Falha na extra√ß√£o
                    st.session_state['texto_anonimizado_arquivo'+VERSION_SUFFIX] = None 
            else: 
                st.error("Motores de anonimiza√ß√£o n√£o est√£o prontos.")
        
        # Mostrar expander do texto original se ele existir no estado da sess√£o
        if st.session_state.get(KEY_TEXTO_ORIGINAL_PDF_DISPLAY, "").strip():
            with st.expander("üìÑ Ver Texto Extra√≠do do PDF (Original)", expanded=False):
                st.text_area("Texto Original:", value=st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY], height=200, disabled=True)

    # Exibir resultados da anonimiza√ß√£o do PDF e op√ß√£o de LLM
    texto_anonimizado_pdf_atual = st.session_state.get('texto_anonimizado_arquivo'+VERSION_SUFFIX)
    if texto_anonimizado_pdf_atual: # Se h√° texto anonimizado do PDF para mostrar
        st.divider()
        st.subheader("Resultado da Anonimiza√ß√£o (Camada 1)")
        st.text_area("Texto Anonimizado (com tags):", value=texto_anonimizado_pdf_atual, height=300, disabled=True) # key removida
        
        col_dl_docx, col_copy_text_file = st.columns([1,1]) 
        with col_dl_docx:
            try:
                docx_bytes = criar_docx_bytes(texto_anonimizado_pdf_atual)
                st.download_button(label="üì• Baixar como .docx", data=docx_bytes, 
                                   file_name=f"anonimizado_{st.session_state.get('nome_arquivo_carregado'+VERSION_SUFFIX, 'arquivo')}.docx", 
                                   mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document", type="secondary")
            except Exception as e: 
                st.error(f"Erro ao gerar DOCX: {e}")
        with col_copy_text_file:
            st_copy_to_clipboard(texto_anonimizado_pdf_atual, "üìã Copiar Texto Anonimizado", key=KEY_COPY_BTN_FILE_ANON)
        
        # Chama a fun√ß√£o gen√©rica para exibir a se√ß√£o LLM
        exibir_secao_llm(texto_anonimizado_pdf_atual, 
                         KEY_LLM_OUTPUT_PDF_STATE, 
                         KEY_LLM_CHOICE_PDF, 
                         KEY_LLM_REWRITE_BTN_PDF, 
                         KEY_COPY_LLM_PDF, 
                         "pdf") # tab_id_suffix para chaves √∫nicas
with tab_texto:
    st.subheader("Passo 1: Insira o texto para anonimizar")
    col_original, col_anonimizado = st.columns(2)
    with col_original:
        st.markdown("##### Texto Original")
        st.text_area("Cole ou digite o texto aqui:", height=300, key=KEY_TEXTO_ORIGINAL_AREA, 
                     help="Insira o texto que voc√™ deseja analisar e anonimizar.")
        st.button("üóëÔ∏è Limpar Tudo (√Årea de Texto)", key=KEY_BOTAO_APAGAR_AREA, on_click=callback_apagar_textos_area, 
                  help="Apaga o texto original, o resultado anonimizado, as entidades detectadas e o resumo da IA para esta aba.")
    with col_anonimizado:
        st.markdown("##### Texto Anonimizado (Camada 1)")
        st.text_area("Resultado da anonimiza√ß√£o (com tags):", 
                     value=st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE, "O resultado da anonimiza√ß√£o aparecer√° aqui..."), 
                     height=300, disabled=True) # key removida
        if st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE) and \
           st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE) not in ["O resultado da anonimiza√ß√£o aparecer√° aqui...", "O resultado da √°rea de texto aparecer√° aqui...", "Erro ao processar o texto da √°rea."]:
            st_copy_to_clipboard(st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE], "üìã Copiar Texto Anonimizado", key=KEY_COPY_BTN_AREA_ANON) # <--- CORRIGIDO AQUI
        else: 
            st.markdown("<div style='height: 38px;'></div>", unsafe_allow_html=True) # Mant√©m alinhamento
    
    st.divider()
    st.subheader("Passo 2: Anonimize o texto da √°rea")
    if st.button("‚ú® Anonimizar Texto da √Årea", type="primary", key=KEY_BOTAO_ANONIMIZAR_AREA, 
                  disabled=(not analyzer_engine or not anonymizer_engine)):
        texto_para_processar = st.session_state.get(KEY_TEXTO_ORIGINAL_AREA, "")
        st.session_state[KEY_LLM_OUTPUT_AREA_STATE] = None # Limpa resumo anterior
        
        if not texto_para_processar.strip():
            st.warning("Por favor, insira um texto na √°rea para anonimizar.")
        elif analyzer_engine and anonymizer_engine:
            try:
                with st.spinner("Analisando e anonimizando o texto da √°rea..."):
                    entidades_para_analise = list(operadores.keys()) + ["SAFE_LOCATION", "LEGAL_HEADER", "ESTADO_CIVIL", "ORGANIZACAO_CONHECIDA"]
                    entidades_para_analise = list(set(entidades_para_analise))
                    if "DEFAULT" in entidades_para_analise: entidades_para_analise.remove("DEFAULT")
                    
                    resultados_analise = analyzer_engine.analyze(text=texto_para_processar, language='pt', entities=entidades_para_analise, return_decision_process=False)
                    resultado_anonimizado_obj = anonymizer_engine.anonymize(text=texto_para_processar, analyzer_results=resultados_analise, operators=operadores)
                
                st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = resultado_anonimizado_obj.text
                
                dados_resultados = []
                if resultados_analise:
                    for res in sorted(resultados_analise, key=lambda x: x.start):
                        dados_resultados.append({
                            "Entidade": res.entity_type, 
                            "Texto Detectado": texto_para_processar[res.start:res.end], 
                            "In√≠cio": res.start, 
                            "Fim": res.end, 
                            "Score": f"{res.score:.2f}"
                        })
                st.session_state['resultados_df_area'+VERSION_SUFFIX] = pd.DataFrame(dados_resultados)
                
                if dados_resultados: 
                    st.success("Texto da √°rea anonimizado e entidades detectadas!")
                else: 
                    st.info("Nenhuma PII detectada no texto da √°rea.")
            except Exception as e:
                st.error(f"Ocorreu um erro durante a anonimiza√ß√£o da √°rea de texto: {e}")
                st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = "Erro ao processar o texto da √°rea."
                st.session_state['resultados_df_area'+VERSION_SUFFIX] = pd.DataFrame()
        else: 
            st.error("Motores de anonimiza√ß√£o n√£o est√£o prontos.")

    # Exibir tabela de entidades detectadas
    # Usando .get() para seguran√ßa, e a chave correta para o dataframe
    df_resultados_atual = st.session_state.get('resultados_df_area'+VERSION_SUFFIX, pd.DataFrame())
    if not df_resultados_atual.empty:
        with st.expander("üìä Ver Entidades Detectadas (do Texto da √Årea Original)", expanded=False):
            st.markdown("As seguintes entidades foram detectadas no texto original da √°rea:")
            st.dataframe(df_resultados_atual, use_container_width=True) 

    # Chamar a fun√ß√£o gen√©rica para exibir a se√ß√£o LLM para a aba de texto
    texto_anonimizado_area_atual = st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE)
    # Condi√ß√£o para evitar mostrar se√ß√£o LLM se o texto for apenas o placeholder inicial ou de erro
    if texto_anonimizado_area_atual and \
       texto_anonimizado_area_atual not in ["O resultado da anonimiza√ß√£o aparecer√° aqui...", 
                                            "O resultado da √°rea de texto aparecer√° aqui...", 
                                            "Erro ao processar o texto da √°rea."]:
        exibir_secao_llm(texto_anonimizado_area_atual, 
                         KEY_LLM_OUTPUT_AREA_STATE, 
                         KEY_LLM_CHOICE_AREA, 
                         KEY_LLM_REWRITE_BTN_AREA, 
                         KEY_COPY_LLM_AREA, 
                         "area") # tab_id_suffix para chaves √∫nicas

# --- Informa√ß√µes na Sidebar ---
st.sidebar.header("Sobre")
sidebar_text_sobre = """
**Anonimizador**

Vers√£o 0.96 (Beta) 

Desenvolvido por:

Juiz Federal Rodrigo Gon√ßalves de Souza
"""
st.sidebar.markdown(sidebar_text_sobre)

st.sidebar.divider()
st.sidebar.markdown(
    "**Como usar:**\n\n"
    "1. **Anonimize seu texto** (Camada 1):\n"
    "   - Na aba 'üóÇÔ∏è Anonimizar Arquivo PDF', carregue um PDF e clique em 'Anonimizar PDF Carregado'. Uma estimativa de tokens ser√° exibida.\n"
    "   - Na aba '‚å®Ô∏è Anonimizar Texto Colado', insira o texto e clique em 'Anonimizar Texto da √Årea'.\n\n"
    "2. **Gere um Resumo Jur√≠dico com IA** (Camada 2 - Opcional):\n"
    "   - Ap√≥s a anonimiza√ß√£o, escolha o modelo de IA desejado na lista suspensa.\n"
    "   - Clique no bot√£o '‚ú® Gerar Resumo'.\n\n"
    "**Importante:**\n"
    "- Trata-se de ferramenta em desenvolvimento.\n"
    "- Sempre confira o resultado gerado (a IA pode cometer erro)."
)
