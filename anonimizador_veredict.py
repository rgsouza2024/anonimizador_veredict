# Vers√£o final (1.0) do Anonimizador Veredict
# Nome do arquivo: anonimizador_veredict.py
# Vers√£o com sidebar ajustada e integra√ß√£o LLM (Claude 3.5 Haiku).

import streamlit as st
import os
from dotenv import load_dotenv # Importa a fun√ß√£o para carregar o .env
load_dotenv()
import spacy
from presidio_analyzer import AnalyzerEngine, PatternRecognizer
from presidio_analyzer.nlp_engine import SpacyNlpEngine
from presidio_analyzer.pattern import Pattern
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig
import pandas as pd
from st_copy_to_clipboard import st_copy_to_clipboard
import io
import fitz  # PyMuPDF
from docx import Document
import re
import os
import anthropic

# --- Constantes ---
NOME_ARQUIVO_SOBRENOMES = "sobrenomes_comuns.txt"
SYSTEM_PROMPT_CLAUDE = "Atue como um especialista em reda√ß√£o jur√≠dica e experi√™ncia no tratamento de documentos anonimizados."
PROMPT_INSTRUCAO_LLM_CLAUDE = """Voc√™ receber√° um texto que foi previamente anonimizado. As informa√ß√µes removidas foram substitu√≠das por tags como <NOME>, <ENDERECO>, <CPF>, etc.. Sua tarefa √© reescrever este texto para que se torne mais fluido, claro e agrad√°vel para leitura. Limite-se ao conte√∫do do texto recebido. N√£o invente, n√£o crie e nem altere informa√ß√µes. Seja descritivo e n√£o fa√ßa ju√≠zo de valor. Ao encontrar uma tag (ex: <NOME>), n√£o tente adivinhar ou recriar a informa√ß√£o original. Em vez disso, reescreva a frase de forma a omitir esse detalhe espec√≠fico ou indique que a informa√ß√£o foi suprimida por raz√µes de privacidade, mantendo o sentido geral do texto. Evite simplesmente substituir a tag por express√µes como '[informa√ß√£o omitida]', buscando uma reda√ß√£o mais natural. Por exemplo, se o texto anonimizado for: "O Sr. <NOME>, CPF <CPF>, contatou a empresa pelo <EMAIL>.", uma reescrita desejada poderia ser: "Um indiv√≠duo contatou a empresa por e-mail. Traga no output apenas o texto reescrito. Nunca apresente frases introdut√≥rias do tipo 'Aqui est√° a vers√£o reescrita do texto...' ou frases de encerramento do tipo 'A reescrita mant√©m a estrutura formal do documento...'."
"""

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Anonimizador Veredict",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Chaves para os widgets e session state ---
KEY_TEXTO_ORIGINAL_AREA = "texto_original_input_area_v6"
KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE = "texto_anonimizado_output_area_state_v6"
KEY_OUTPUT_PDF_ANONIMIZADO_DISPLAY_STATE = "output_pdf_anonimizado_display_state_v6" 
KEY_PDF_UPLOADER = "pdf_uploader_v6"
KEY_BOTAO_ANONIMIZAR_PDF = "botao_anonimizar_pdf_v6"
KEY_BOTAO_APAGAR_AREA = "botao_apagar_area_v6"
KEY_BOTAO_ANONIMIZAR_AREA = "botao_anonimizar_area_v6"
KEY_COPY_BTN_FILE = "copy_btn_file_v6"
KEY_COPY_BTN_AREA = "copy_btn_area_v6"
KEY_TEXTO_ORIGINAL_PDF_DISPLAY = "texto_original_pdf_exp_v6"
KEY_LLM_REWRITE_BTN_PDF = "llm_rewrite_pdf_v6"
KEY_LLM_REWRITE_BTN_AREA = "llm_rewrite_area_v6"
KEY_LLM_OUTPUT_PDF_STATE = "llm_output_pdf_state_v6"
KEY_LLM_OUTPUT_AREA_STATE = "llm_output_area_state_v6"
KEY_COPY_LLM_PDF = "copy_llm_pdf_v6"
KEY_COPY_LLM_AREA = "copy_llm_area_v6"

# --- Fun√ß√µes de Callback e Utilit√°rias ---
def callback_apagar_textos_area():
    st.session_state[KEY_TEXTO_ORIGINAL_AREA] = ""
    st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = "O resultado da anonimiza√ß√£o aparecer√° aqui..."
    if 'resultados_df_area' in st.session_state:
        st.session_state.resultados_df_area = pd.DataFrame()
    if KEY_LLM_OUTPUT_AREA_STATE in st.session_state:
        st.session_state[KEY_LLM_OUTPUT_AREA_STATE] = None
    if 'nome_arquivo_carregado' in st.session_state:
        del st.session_state.nome_arquivo_carregado
    if 'texto_anonimizado_arquivo' in st.session_state: 
        st.session_state.texto_anonimizado_arquivo = None
    if KEY_TEXTO_ORIGINAL_PDF_DISPLAY in st.session_state:
        st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = ""
    if KEY_LLM_OUTPUT_PDF_STATE in st.session_state:
        st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None

def carregar_lista_de_arquivo(nome_arquivo):
    lista_itens = []
    caminho_base = os.path.dirname(__file__)
    caminho_arquivo = os.path.join(caminho_base, nome_arquivo)
    try:
        with open(caminho_arquivo, "r", encoding="utf-8") as f:
            for linha in f:
                item = linha.strip()
                if item:
                    lista_itens.append(item)
        if not lista_itens and os.path.exists(caminho_arquivo):
            st.warning(f"O arquivo de lista '{nome_arquivo}' foi encontrado na pasta do script, mas est√° vazio ou n√£o cont√©m itens v√°lidos.")
    except FileNotFoundError:
        st.warning(f"Arquivo de lista '{nome_arquivo}' n√£o encontrado. O reconhecedor de sobrenomes n√£o ser√° carregado com esta lista.")
    except Exception as e:
        st.error(f"Erro ao ler o arquivo de lista '{nome_arquivo}': {e}")
    return lista_itens

# --- Listas Est√°ticas (Completas, conforme fornecido pelo usu√°rio) ---
LISTA_ESTADOS_CAPITAIS_BR = [
    "Acre", "Alagoas", "Amap√°", "Amazonas", "Bahia", "Cear√°", "Distrito Federal", "DF",
    "Esp√≠rito Santo", "Goi√°s", "GO", "Maranh√£o", "MA", "Mato Grosso", "Mato Grosso do Sul",
    "Minas Gerais", "MG", "Par√°", "Para√≠ba", "Paran√°", "Pernambuco", "Piau√≠",
    "Rio de Janeiro", "RJ", "Rio Grande do Norte", "Rio Grande do Sul", "Rond√¥nia",
    "Roraima", "Santa Catarina", "SC", "S√£o Paulo", "SP", "Sergipe", "Tocantins",
    "Rio Branco", "Macei√≥", "Macap√°", "Manaus", "Salvador", "Fortaleza", "Bras√≠lia",
    "Vit√≥ria", "Goi√¢nia", "S√£o Lu√≠s", "Cuiab√°", "Campo Grande", "Belo Horizonte",
    "Bel√©m", "Jo√£o Pessoa", "Curitiba", "Recife", "Teresina",
    "Natal", "Porto Alegre", "Porto Velho", "Boa Vista", "Florian√≥polis",
    "Aracaju", "Palmas"
]
TERMOS_CABECALHO_LEGAL_NAO_ANONIMIZAR = [
    "EXMO. SR. DR. JUIZ FEDERAL", "EXMO SR DR JUIZ FEDERAL",
    "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ FEDERAL", "JUIZ FEDERAL",
    "EXMO. SR. DR. JUIZ DE DIREITO", "EXMO SR DR JUIZ DE DIREITO",
    "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ DE DIREITO", "JUIZ DE DIREITO",
    "JUIZADO ESPECIAL FEDERAL", "VARA DA SE√á√ÉO JUDICI√ÅRIA", "SE√á√ÉO JUDICI√ÅRIA", "EXMO.",
    "EXMO", "SR.", "DR.", "Dra.", "DRA."
]
LISTA_ESTADO_CIVIL = [
    "casado", "casada", "solteiro", "solteira", "vi√∫vo", "vi√∫va", 
    "divorciado", "divorciada", "separado", "separada", "unido", "unida",
    "companheiro", "companheira"
]
LISTA_ORGANIZACOES_CONHECIDAS = [
    "SIAPE", "FUNASA", "INSS", "IBAMA", "CNPQ", "IBGE", "FIOCRUZ", "SERPRO", "DATAPREV"
]

LISTA_SOBRENOMES_FREQUENTES_BR = carregar_lista_de_arquivo(NOME_ARQUIVO_SOBRENOMES)

# --- Configura√ß√£o e Inicializa√ß√£o do Presidio ---
@st.cache_resource
def carregar_analyzer_engine(termos_safe_location, termos_legal_header, lista_sobrenomes,
                             termos_estado_civil, termos_organizacoes_conhecidas):
    try:
        try: spacy.load('pt_core_news_lg')
        except OSError:
            st.error("Modelo spaCy 'pt_core_news_lg' n√£o encontrado. Instale com: python -m spacy download pt_core_news_lg")
            return None
        spacy_engine_obj = SpacyNlpEngine(models=[{'lang_code': 'pt', 'model_name': 'pt_core_news_lg'}])
        analyzer = AnalyzerEngine(nlp_engine=spacy_engine_obj, supported_languages=["pt"], default_score_threshold=0.4)
        
        recognizer_safe_location = PatternRecognizer(supported_entity="SAFE_LOCATION", name="SafeLocationRecognizer", deny_list=termos_safe_location, supported_language="pt", deny_list_score=0.99)
        analyzer.registry.add_recognizer(recognizer_safe_location)
        recognizer_legal_header = PatternRecognizer(supported_entity="LEGAL_HEADER", name="LegalHeaderRecognizer", deny_list=termos_legal_header, supported_language="pt", deny_list_score=0.99)
        analyzer.registry.add_recognizer(recognizer_legal_header)
        cpf_pattern = Pattern(name="CpfRegexPattern", regex=r"\b\d{3}\.\d{3}\.\d{3}-\d{2}\b", score=0.85)
        cpf_recognizer = PatternRecognizer(supported_entity="CPF", name="CustomCpfRecognizer", patterns=[cpf_pattern], supported_language="pt")
        analyzer.registry.add_recognizer(cpf_recognizer)
        oab_pattern = Pattern(name="OabRegexPattern", regex=r"\b(?:OAB\s+)?\d{1,6}(?:\.\d{3})?\s*\/\s*[A-Z]{2}\b", score=0.85)
        oab_recognizer = PatternRecognizer(supported_entity="OAB_NUMBER", name="CustomOabRecognizer", patterns=[oab_pattern], supported_language="pt")
        analyzer.registry.add_recognizer(oab_recognizer)
        cep_pattern = Pattern(name="CepPattern", regex=r"\b(\d{5}-?\d{3}|\d{2}\.\d{3}-?\d{3})\b", score=0.80) 
        cep_recognizer = PatternRecognizer(supported_entity="CEP_NUMBER", name="CustomCepRecognizer", patterns=[cep_pattern], supported_language="pt")
        analyzer.registry.add_recognizer(cep_recognizer)

        if termos_estado_civil:
            estado_civil_patterns = [Pattern(name=f"estado_civil_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in termos_estado_civil]
            ec_recognizer = PatternRecognizer(supported_entity="ESTADO_CIVIL", name="EstadoCivilRecognizer", patterns=estado_civil_patterns, supported_language="pt")
            analyzer.registry.add_recognizer(ec_recognizer)
        if termos_organizacoes_conhecidas:
            org_patterns = [Pattern(name=f"org_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in termos_organizacoes_conhecidas]
            org_recognizer = PatternRecognizer(supported_entity="ORGANIZACAO_CONHECIDA", name="OrganizacaoConhecidaRecognizer", patterns=org_patterns, supported_language="pt")
            analyzer.registry.add_recognizer(org_recognizer)
        if lista_sobrenomes:
            surnames_patterns = [Pattern(name=f"surname_{s.lower().replace(' ', '_')}", regex=rf"(?i)\b{re.escape(s)}\b", score=0.95) for s in lista_sobrenomes]
            surnames_recognizer = PatternRecognizer(supported_entity="PERSON", name="BrazilianCommonSurnamesRecognizer", patterns=surnames_patterns, supported_language="pt")
            analyzer.registry.add_recognizer(surnames_recognizer)
        
        return analyzer
    except Exception as e:
        st.error(f"Erro cr√≠tico ao carregar o AnalyzerEngine: {e}.")
        return None

@st.cache_resource
def carregar_anonymizer_engine():
    try:
        engine = AnonymizerEngine()
        return engine
    except Exception as e:
        st.error(f"Erro cr√≠tico ao carregar o AnonymizerEngine: {e}.")
        return None

def obter_operadores_anonimizacao():
    return {
        "DEFAULT": OperatorConfig("keep"),
        "PERSON": OperatorConfig("replace", {"new_value": "<NOME>"}),
        "LOCATION": OperatorConfig("replace", {"new_value": "<ENDERECO>"}),
        "EMAIL_ADDRESS": OperatorConfig("replace", {"new_value": "<EMAIL>"}),
        "PHONE_NUMBER": OperatorConfig("mask", {"type": "mask", "masking_char": "*", "chars_to_mask": 4, "from_end": True}),
        "CPF": OperatorConfig("replace", {"new_value": "<CPF>"}),
        "DATE_TIME": OperatorConfig("replace", {"new_value": "<DATA>"}),
        "OAB_NUMBER": OperatorConfig("replace", {"new_value": "<OAB>"}),
        "CEP_NUMBER": OperatorConfig("replace", {"new_value": "<CEP>"}),
        "ESTADO_CIVIL": OperatorConfig("keep"),
        "ORGANIZACAO_CONHECIDA": OperatorConfig("keep")
    }

analyzer_engine = carregar_analyzer_engine(
    LISTA_ESTADOS_CAPITAIS_BR,
    TERMOS_CABECALHO_LEGAL_NAO_ANONIMIZAR,
    LISTA_SOBRENOMES_FREQUENTES_BR,
    LISTA_ESTADO_CIVIL,
    LISTA_ORGANIZACOES_CONHECIDAS
)
anonymizer_engine = carregar_anonymizer_engine()
operadores = obter_operadores_anonimizacao()

def extrair_texto_de_pdf(arquivo_pdf_bytes):
    texto_completo = ""
    try:
        documento_pdf = fitz.open(stream=arquivo_pdf_bytes, filetype="pdf")
        for pagina in documento_pdf: texto_completo += pagina.get_text()
        documento_pdf.close()
    except Exception as e: st.error(f"Erro ao extrair texto do PDF: {e}"); return None
    return texto_completo

def criar_docx_bytes(texto_anonimizado):
    documento = Document(); documento.add_paragraph(texto_anonimizado)
    bio = io.BytesIO(); documento.save(bio); bio.seek(0)
    return bio.getvalue()

def carregar_chave_anthropic():
    api_key = os.getenv("ANTHROPIC_API_KEY") 
    if not api_key: 
        try:
            if hasattr(st, 'secrets') and st.secrets.get("ANTHROPIC_API_KEY"):
                api_key = st.secrets["ANTHROPIC_API_KEY"]
        except FileNotFoundError: pass 
        except Exception as e: st.warning(f"Problema ao acessar st.secrets para Anthropic: {e}")
    if not api_key:
        st.error("Chave API da Anthropic n√£o configurada. Defina ANTHROPIC_API_KEY.")
        return None
    return api_key

def reescrever_texto_com_claude(texto_anonimizado: str, prompt_instrucao_usuario: str, system_prompt: str, api_key: str) -> str | None:
    if not texto_anonimizado or not texto_anonimizado.strip():
        st.warning("N√£o h√° texto anonimizado para reescrever.")
        return None
    try:
        client = anthropic.Anthropic(api_key=api_key)
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=len(texto_anonimizado.split()) + 8000, 
            temperature=0.3,
            system=system_prompt,
            messages=[{"role": "user", "content": f"{prompt_instrucao_usuario}\n\nTexto anonimizado para reescrever:\n\n---\n{texto_anonimizado}\n---"}]
        )
        if response.content and isinstance(response.content, list) and len(response.content) > 0:
            texto_reescrito_partes = [block.text for block in response.content if block.type == 'text']
            return "".join(texto_reescrito_partes).strip() if texto_reescrito_partes else None
        st.error("A LLM n√£o retornou uma resposta de texto v√°lida.")
        return None
    except anthropic.APIConnectionError as e: st.error(f"Erro de conex√£o com a API da Anthropic: {e}")
    except anthropic.RateLimitError as e: st.error(f"Limite de requisi√ß√µes da API da Anthropic atingido: {e}")
    except anthropic.AuthenticationError: st.error("Erro de autentica√ß√£o com a API da Anthropic. Verifique sua chave API.")
    except anthropic.APIError as e: st.error(f"Erro na API da Anthropic: {e}")
    except Exception as e: st.error(f"Ocorreu um erro inesperado ao processar com a LLM: {e}")
    return None

# --- Interface Streamlit Principal ---
path_da_logo = "logo_veredict.png"
try: st.image(path_da_logo, width=420)
except: st.warning("Logo n√£o p√¥de ser carregada.")
st.markdown("<h1 style='text-align: center; margin-bottom: 20px;'>Anonimizador Veredict</h1>", unsafe_allow_html=True)

tab_pdf, tab_texto = st.tabs(["üóÇÔ∏è Anonimizar Arquivo PDF", "‚å®Ô∏è Anonimizar Texto Colado"])

st.session_state.setdefault(KEY_LLM_OUTPUT_PDF_STATE, None)
st.session_state.setdefault(KEY_LLM_OUTPUT_AREA_STATE, None)
st.session_state.setdefault('texto_anonimizado_arquivo', None)
st.session_state.setdefault(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE, "O resultado da √°rea de texto aparecer√° aqui...")
st.session_state.setdefault(KEY_TEXTO_ORIGINAL_PDF_DISPLAY, "")
st.session_state.setdefault('nome_arquivo_carregado', None)
st.session_state.setdefault('resultados_df_area', pd.DataFrame())
st.session_state.setdefault(KEY_TEXTO_ORIGINAL_AREA, ("EXMO. SR. DR. JUIZ FEDERAL DA ____¬™ VARA DA SE√á√ÉO JUDICI√ÅRIA DE S√ÉO LU√çS ‚Äì MA ‚Äì JUIZADO ESPECIAL FEDERAL.\n"
                                                     "Jo√£o Silva, casado, RG 123456 SSP/MA, CPF 123.456.789-00, SIAPE 12345, FUNASA.\n" # Ajustado o nome para o exemplo
                                                     "Com CEP residencial √© 70423-673 e o comercial √© 70423673. Outro CEP: 70.423673.\n"
                                                     "Contato por email joao.silva@emailficticio.com e meu telefone √© (21) 98765-4321."))

with tab_pdf:
    st.header("Processar Arquivo PDF")
    arquivo_pdf_carregado = st.file_uploader("Escolha um arquivo PDF:", type=["pdf"], key=KEY_PDF_UPLOADER, help="Fa√ßa o upload de um arquivo PDF para extrair o texto e anonimiz√°-lo.")

    if arquivo_pdf_carregado is not None:
        if st.session_state.nome_arquivo_carregado != arquivo_pdf_carregado.name:
            st.session_state.nome_arquivo_carregado = arquivo_pdf_carregado.name
            st.session_state.texto_anonimizado_arquivo = None 
            st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = "" 
            st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None

        if st.button("üîç Anonimizar PDF Carregado", key=KEY_BOTAO_ANONIMIZAR_PDF, type="primary", disabled=(not analyzer_engine or not anonymizer_engine)):
            if analyzer_engine and anonymizer_engine:
                with st.spinner(f"Processando '{arquivo_pdf_carregado.name}'..."):
                    bytes_pdf = arquivo_pdf_carregado.getvalue()
                    texto_extraido = extrair_texto_de_pdf(bytes_pdf)
                    st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY] = texto_extraido if texto_extraido else ""
                    st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = None
                    if texto_extraido and texto_extraido.strip():
                        entidades_para_analise = list(operadores.keys()) + ["SAFE_LOCATION", "LEGAL_HEADER", "ESTADO_CIVIL", "ORGANIZACAO_CONHECIDA"]
                        entidades_para_analise = list(set(entidades_para_analise)); 
                        if "DEFAULT" in entidades_para_analise: entidades_para_analise.remove("DEFAULT")
                        resultados_analise_pdf = analyzer_engine.analyze(text=texto_extraido, language='pt', entities=entidades_para_analise, return_decision_process=False)
                        resultado_anonimizado_pdf_obj = anonymizer_engine.anonymize(text=texto_extraido, analyzer_results=resultados_analise_pdf, operators=operadores)
                        st.session_state.texto_anonimizado_arquivo = resultado_anonimizado_pdf_obj.text
                        st.success(f"Arquivo '{arquivo_pdf_carregado.name}' anonimizado com sucesso!")
                    elif texto_extraido is not None: st.warning("O PDF carregado parece n√£o conter texto √∫til.")
                    else: st.session_state.texto_anonimizado_arquivo = None 
            else: st.error("Motores de anonimiza√ß√£o n√£o est√£o prontos.")
        
        if st.session_state.get(KEY_TEXTO_ORIGINAL_PDF_DISPLAY, "").strip():
            with st.expander("üìÑ Ver Texto Extra√≠do do PDF (Original)", expanded=False):
                st.text_area("Texto Original:", value=st.session_state[KEY_TEXTO_ORIGINAL_PDF_DISPLAY], height=200, disabled=True)

    texto_anonimizado_pdf_atual = st.session_state.get('texto_anonimizado_arquivo')
    if texto_anonimizado_pdf_atual:
        st.subheader("Texto Anonimizado do Arquivo PDF")
        st.text_area("Resultado do arquivo:", value=texto_anonimizado_pdf_atual, height=300, disabled=True)
        col_dl_docx, col_copy_text_file = st.columns(2) 
        with col_dl_docx:
            try:
                docx_bytes = criar_docx_bytes(texto_anonimizado_pdf_atual)
                st.download_button(label="üì• Baixar como .docx", data=docx_bytes, file_name=f"anonimizado_{st.session_state.get('nome_arquivo_carregado', 'arquivo')}.docx", 
                                   mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document", type="secondary")
            except Exception as e: st.error(f"Erro ao gerar DOCX: {e}")
        with col_copy_text_file:
            st_copy_to_clipboard(texto_anonimizado_pdf_atual, "üìã Copiar Texto Gerado", key=KEY_COPY_BTN_FILE)

        st.divider()
        st.subheader("Melhorar Fluidez do Texto Anonimizado com Intelig√™ncia Artificial")
        if st.button("‚ú® Gerar Texto Reescrito pela IA", key=KEY_LLM_REWRITE_BTN_PDF, type="primary"):
            anthropic_api_key = carregar_chave_anthropic()
            if anthropic_api_key and texto_anonimizado_pdf_atual:
                with st.spinner("Trabalhando na reescrita... Por favor, aguarde."):
                    texto_reescrito = reescrever_texto_com_claude(texto_anonimizado_pdf_atual, PROMPT_INSTRUCAO_LLM_CLAUDE, SYSTEM_PROMPT_CLAUDE, anthropic_api_key)
                    st.session_state[KEY_LLM_OUTPUT_PDF_STATE] = texto_reescrito
            elif not anthropic_api_key: pass 
            elif not texto_anonimizado_pdf_atual: st.warning("N√£o h√° texto anonimizado do PDF para reescrever.")

        texto_llm_pdf_atual = st.session_state.get(KEY_LLM_OUTPUT_PDF_STATE)
        if texto_llm_pdf_atual:
            st.text_area("Texto Reescrito com Intelig√™ncia Artificial:", value=texto_llm_pdf_atual, height=300, disabled=True)
            st_copy_to_clipboard(texto_llm_pdf_atual, "üìã Copiar Texto Reescrito", key=KEY_COPY_LLM_PDF)
        elif texto_anonimizado_pdf_atual: 
            st.caption("Clique no bot√£o acima para gerar uma vers√£o reescrita e mais fluida do texto anonimizado do PDF.")

with tab_texto:
    st.header("Analisar Texto Colado")
    
    col_original, col_anonimizado = st.columns(2)
    with col_original:
        st.subheader("Texto Original")
        # Removido o 'value=' expl√≠cito, pois a 'key' e setdefault cuidam disso.
        st.text_area("Cole ou digite o texto para anonimizar:", height=300, key=KEY_TEXTO_ORIGINAL_AREA, 
                     help="Insira o texto que voc√™ deseja analisar e anonimizar.")
        st.button("üóëÔ∏è Limpar √Årea de Texto", key=KEY_BOTAO_APAGAR_AREA, on_click=callback_apagar_textos_area, help="Apaga o texto original, o resultado anonimizado e as entidades detectadas.")
    with col_anonimizado:
        st.subheader("Texto Anonimizado")
        st.text_area("Resultado da anonimiza√ß√£o:", value=st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE, "O resultado da √°rea de texto aparecer√° aqui..."), 
                     height=300, disabled=True) # KEY REMOVIDA
        if st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE) and \
           st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE) not in ["O resultado da √°rea de texto aparecer√° aqui...", "Erro ao processar o texto da √°rea."]:
            st_copy_to_clipboard(st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE], "üìã Copiar Texto Anonimizado", key=KEY_COPY_BTN_AREA)
        else: st.markdown("<div style='height: 38px;'></div>", unsafe_allow_html=True)
    
    st.divider()

    if st.button("‚ú® Anonimizar Texto da √Årea", type="primary", key=KEY_BOTAO_ANONIMIZAR_AREA,
                  disabled=(not analyzer_engine or not anonymizer_engine)):
        texto_para_processar = st.session_state[KEY_TEXTO_ORIGINAL_AREA]
        st.session_state[KEY_LLM_OUTPUT_AREA_STATE] = None
        if not texto_para_processar.strip():
            st.warning("Por favor, insira um texto na √°rea para anonimizar.")
        elif analyzer_engine and anonymizer_engine:
            try:
                with st.spinner("Analisando e anonimizando o texto da √°rea..."):
                    entidades_para_analise = list(operadores.keys()) + ["SAFE_LOCATION", "LEGAL_HEADER", "ESTADO_CIVIL", "ORGANIZACAO_CONHECIDA"]
                    entidades_para_analise = list(set(entidades_para_analise))
                    if "DEFAULT" in entidades_para_analise: entidades_para_analise.remove("DEFAULT")
                    resultados_analise = analyzer_engine.analyze(text=texto_para_processar, language='pt', entities=entidades_para_analise, return_decision_process=False)
                    resultado_anonimizado_obj = anonymizer_engine.anonymize(text=texto_para_processar, analyzer_results=resultados_analise, operators=operadores)
                st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = resultado_anonimizado_obj.text
                dados_resultados = []
                if resultados_analise:
                    for res in sorted(resultados_analise, key=lambda x: x.start):
                        dados_resultados.append({"Entidade": res.entity_type, "Texto Detectado": texto_para_processar[res.start:res.end], 
                                                 "In√≠cio": res.start, "Fim": res.end, "Score": f"{res.score:.2f}"})
                st.session_state.resultados_df_area = pd.DataFrame(dados_resultados)
                if dados_resultados: st.success("Texto da √°rea anonimizado e entidades detectadas!")
                else: st.info("Nenhuma PII detectada no texto da √°rea.")
            except Exception as e:
                st.error(f"Ocorreu um erro durante a anonimiza√ß√£o da √°rea de texto: {e}")
                st.session_state[KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE] = "Erro ao processar o texto da √°rea."
                st.session_state.resultados_df_area = pd.DataFrame()
        else: st.error("Motores de anonimiza√ß√£o n√£o est√£o prontos.")

    if not st.session_state.get('resultados_df_area', pd.DataFrame()).empty:
        with st.expander("üìä Ver Entidades Detectadas (da √Årea de Texto)", expanded=False):
            st.markdown("As seguintes entidades foram detectadas no texto original da √°rea:")
            st.dataframe(st.session_state.resultados_df_area, use_container_width=True) 

    texto_anonimizado_area_atual = st.session_state.get(KEY_TEXTO_ANONIMIZADO_OUTPUT_AREA_STATE)
    if texto_anonimizado_area_atual and texto_anonimizado_area_atual not in ["O resultado da √°rea de texto aparecer√° aqui...", "Erro ao processar o texto da √°rea."]:
        st.divider()
        st.subheader("Melhorar Fluidez do Texto Anonimizado com Intelig√™ncia Artificial")
        if st.button("‚ú® Gerar Texto Reescrito pela IA", key=KEY_LLM_REWRITE_BTN_AREA, type="primary"):
            anthropic_api_key = carregar_chave_anthropic()
            if anthropic_api_key and texto_anonimizado_area_atual:
                with st.spinner("Trabalhando na reescrita... Por favor, aguarde."):
                    texto_reescrito = reescrever_texto_com_claude(texto_anonimizado_area_atual, PROMPT_INSTRUCAO_LLM_CLAUDE, SYSTEM_PROMPT_CLAUDE, anthropic_api_key)
                    st.session_state[KEY_LLM_OUTPUT_AREA_STATE] = texto_reescrito
            elif not anthropic_api_key: pass
        
        texto_llm_area_atual = st.session_state.get(KEY_LLM_OUTPUT_AREA_STATE)
        if texto_llm_area_atual:
            st.text_area("Texto Reescrito pela Intelig√™ncia Artificial:", value=texto_llm_area_atual, height=300, disabled=True) # KEY REMOVIDA
            st_copy_to_clipboard(texto_llm_area_atual, "üìã Copiar Texto Reescrito", key=KEY_COPY_LLM_AREA)
        elif texto_anonimizado_area_atual and texto_anonimizado_area_atual not in ["O resultado da √°rea de texto aparecer√° aqui...", "Erro ao processar o texto da √°rea."]:
            st.caption("Clique no bot√£o acima para gerar uma vers√£o reescrita e mais fluida do texto anonimizado da √°rea.")

# --- Informa√ß√µes na Sidebar ---
st.sidebar.header("Sobre")
sidebar_text_sobre = """
**Anonimizador Veredict**

Vers√£o 1.0 (Beta) 

Desenvolvido por:

Juiz Federal Rodrigo Gon√ßalves de Souza
"""
st.sidebar.markdown(sidebar_text_sobre) # Nome da vari√°vel corrigido para evitar conflito com o nome do m√≥dulo 'sidebar_text' se existisse

st.sidebar.divider()
st.sidebar.markdown(
    "**Como usar:**\n\n"
    "1. **Anonimize seu texto** (via PDF ou colando na √°rea de texto apropriada).\n"
    "   - Na aba 'üóÇÔ∏è Anonimizar Arquivo PDF', carregue um PDF e clique em 'Anonimizar PDF Carregado'.\n"
    "   - Na aba '‚å®Ô∏è Anonimizar Texto Colado', insira o texto e clique em 'Anonimizar Texto da √Årea'.\n\n"
    "2. **Melhore a Fluidez com IA (Opcional):**\n"
    "   - Ap√≥s a anonimiza√ß√£o, se desejar uma vers√£o do texto mais fluida (sem as tags de anonimiza√ß√£o expl√≠citas),"
    " clique no bot√£o '‚ú® Gerar Texto Reescrito pela IA'.\n\n"
    "**Importante:**\n"
    "- Trata-se de ferramenta em desenvolvimento.\n"
    "- Sempre confira o resultado gerado (a IA pode cometer erros)."
)