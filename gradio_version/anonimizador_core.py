import os
import PyPDF2
import io
import re
import spacy
from presidio_analyzer import AnalyzerEngine, PatternRecognizer
from presidio_analyzer.nlp_engine import SpacyNlpEngine
from presidio_analyzer.pattern import Pattern
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig

class AnonimizadorCore:
    """Classe principal para anonimiza√ß√£o de documentos usando Microsoft Presidio com configura√ß√£o avan√ßada para portugu√™s brasileiro"""
    
    def __init__(self):
        self.modelos_disponiveis = {
            "GPT-4": "openai",
            "Claude": "anthropic", 
            "Gemini": "google",
            "Groq": "groq",
            "Ollama": "ollama"
        }
        
        # Carregar listas de termos brasileiros
        self._carregar_listas_brasileiras()
        
        # Configurar NLP Engine com spaCy portugu√™s
        try:
            spacy.load('pt_core_news_lg')
            spacy_engine_obj = SpacyNlpEngine(models=[{'lang_code': 'pt', 'model_name': 'pt_core_news_lg'}])
            self.analyzer = AnalyzerEngine(nlp_engine=spacy_engine_obj, supported_languages=["pt"], default_score_threshold=0.4)
            print("‚úÖ Engine spaCy portugu√™s configurado com sucesso!")
        except OSError:
            print("‚ö†Ô∏è Modelo spaCy 'pt_core_news_lg' n√£o encontrado. Usando configura√ß√£o b√°sica.")
            self.analyzer = AnalyzerEngine()
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao configurar NLP Engine: {e}")
            self.analyzer = AnalyzerEngine()
        
        # Inicializar anonymizer engine
        self.anonymizer = AnonymizerEngine()
        
        # Adicionar reconhecedores personalizados para portugu√™s brasileiro
        self._adicionar_reconhecedores_pt_br()
    
    def _carregar_listas_brasileiras(self):
        """Carrega as listas de termos espec√≠ficos brasileiros"""
        # Estados e capitais brasileiras (n√£o anonimizar)
        self.estados_capitais = [
            "Acre", "AC", "Alagoas", "AL", "Amap√°", "AP", "Amazonas", "AM", "Bahia", "BA",
            "Cear√°", "CE", "Distrito Federal", "DF", "Esp√≠rito Santo", "ES", "Goi√°s", "GO",
            "Maranh√£o", "MA", "Mato Grosso", "MT", "Mato Grosso do Sul", "MS", "Minas Gerais", "MG",
            "Par√°", "PA", "Para√≠ba", "PB", "Paran√°", "PR", "Pernambuco", "PE", "Piau√≠", "PI",
            "Rio de Janeiro", "RJ", "Rio Grande do Norte", "RN", "Rio Grande do Sul", "RS",
            "Rond√¥nia", "RO", "Roraima", "RR", "Santa Catarina", "SC", "S√£o Paulo", "SP",
            "Sergipe", "SE", "Tocantins", "TO", "Aracaju", "Bel√©m", "Belo Horizonte", "Boa Vista",
            "Bras√≠lia", "Campo Grande", "Cuiab√°", "Curitiba", "Florian√≥polis", "Fortaleza",
            "Goi√¢nia", "Jo√£o Pessoa", "Macap√°", "Macei√≥", "Manaus", "Natal", "Palmas",
            "Porto Alegre", "Porto Velho", "Recife", "Rio Branco", "Salvador", "S√£o Lu√≠s",
            "S√£o Paulo", "Teresina", "Vit√≥ria"
        ]
        
        # Termos de cabe√ßalho legal (n√£o anonimizar)
        self.termos_legal_header = [
            "EXMO. SR. DR. JUIZ FEDERAL", "EXMO SR DR JUIZ FEDERAL",
            "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ FEDERAL", "JUIZ FEDERAL",
            "EXMO. SR. DR. JUIZ DE DIREITO", "EXMO SR DR JUIZ DE DIREITO",
            "EXCELENT√çSSIMO SENHOR DOUTOR JUIZ DE DIREITO", "JUIZ DE DIREITO",
            "JUIZADO ESPECIAL FEDERAL", "VARA DA SE√á√ÉO JUDICI√ÅRIA", "SE√á√ÉO JUDICI√ÅRIA", "EXMO.",
            "EXMO", "SR.", "DR.", "Dra.", "DRA.", "EXCELENT√çSSIMO(A) SENHOR(A) DOUTOR(A) JUIZ(A) FEDERAL",
            "EXCELENT√çSSIMO", "Senhor", "Doutor", "Senhora", "Doutora", "EXCELENT√çSSIMA", "EXCELENT√çSSIMO(A)",
            "Senhor(a)", "Doutor(a)", "Juiz", "Ju√≠za", "Juiz(a)", "Juiz(√≠za)", "Assunto", "Assuntos"
        ]
        
        # Estado civil
        self.estado_civil = [
            "casado", "casada", "solteiro", "solteira", "vi√∫vo", "vi√∫va", 
            "divorciado", "divorciada", "separado", "separada", "unido", "unida",
            "companheiro", "companheira", "amasiado", "amasiada", "uni√£o est√°vel",
            "em uni√£o est√°vel"
        ]
        
        # Organiza√ß√µes conhecidas
        self.organizacoes_conhecidas = [
            "SIAPE", "FUNASA", "INSS", "IBAMA", "CNPQ", "IBGE", "FIOCRUZ",
            "SERPRO", "DATAPREV", "VALOR", "Justi√ßa", "Justica", "Segredo", "PJe",
            "Assunto", "Tribunal Regional Federal", "Assuntos", "Vara Federal",
            "Vara", "Justi√ßa Federal", "Federal", "Juizado", "Especial", "Federal",
            "Vara Federal de Juizado Especial C√≠vel", "Turma", "Turma Recursal", "PJE",
            "SJGO", "SJDF", "SJMA", "SJAC", "SJAL", "SJAP", "SJAM", "SJBA", "SJCE", 
            "SJDF", "SJES", "SJGO", "SJMA", "SJMG", "SJMS", "SJMT", "SJPA", "SJPB", 
            "SJPE", "SJPI", "SJPR", "SJPE", "SJRN", "SJRO", "SJRR", "SJRS", "SJSC",
            "SJSE", "SJSP", "SJTO", "Justi√ßa Federal da 1¬™ Regi√£o", "PJe - Processo Judicial Eletr√¥nico"
        ]
        
        # Carregar sobrenomes comuns do arquivo
        self.sobrenomes_comuns = self._carregar_sobrenomes_comuns()
        
        # Termos comuns a manter
        self.termos_comuns = self._carregar_termos_comuns()
    
    def _carregar_sobrenomes_comuns(self):
        """Carrega a lista de sobrenomes comuns brasileiros"""
        caminho = os.path.join(os.path.dirname(__file__), "sobrenomes_comuns.txt")
        try:
            with open(caminho, encoding="utf-8") as f:
                return [linha.strip() for linha in f if linha.strip()]
        except Exception:
            return []

    def _carregar_termos_comuns(self):
        """Carrega a lista de termos comuns"""
        caminho = os.path.join(os.path.dirname(__file__), "termos_comuns.txt")
        try:
            with open(caminho, encoding="utf-8") as f:
                return [linha.strip() for linha in f if linha.strip()]
        except Exception:
            return []
    
    def _adicionar_reconhecedores_pt_br(self):
        """Adiciona reconhecedores personalizados avan√ßados para portugu√™s brasileiro"""
        try:
            # Reconhecedor para Locais Seguros (Estados e Capitais)
            if self.estados_capitais:
                recognizer_safe_location = PatternRecognizer(
                    supported_entity="SAFE_LOCATION", 
                    name="SafeLocationRecognizer", 
                    deny_list=self.estados_capitais, 
                    supported_language="pt", 
                    deny_list_score=0.99
                )
                self.analyzer.registry.add_recognizer(recognizer_safe_location)
            
            # Reconhecedor para Cabe√ßalhos Legais
            if self.termos_legal_header:
                recognizer_legal_header = PatternRecognizer(
                    supported_entity="LEGAL_HEADER", 
                    name="LegalHeaderRecognizer", 
                    deny_list=self.termos_legal_header, 
                    supported_language="pt", 
                    deny_list_score=0.99
                )
                self.analyzer.registry.add_recognizer(recognizer_legal_header)
            
            # Reconhecedor para CPF (padr√£o avan√ßado)
            cpf_pattern = Pattern(name="CpfRegexPattern", regex=r"\b\d{3}\.\d{3}\.\d{3}-\d{2}\b", score=0.85)
            cpf_recognizer = PatternRecognizer(
                supported_entity="CPF", 
                name="CustomCpfRecognizer", 
                patterns=[cpf_pattern], 
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(cpf_recognizer)
            
            # Reconhecedor para OAB_NUMBER (padr√£o avan√ßado)
            oab_pattern = Pattern(name="OabRegexPattern", regex=r"\b(?:OAB\s+)?\d{1,6}(?:\.\d{3})?\s*\/\s*[A-Z]{2}\b", score=0.85)
            oab_recognizer = PatternRecognizer(
                supported_entity="OAB_NUMBER", 
                name="CustomOabRecognizer", 
                patterns=[oab_pattern], 
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(oab_recognizer)

            # Reconhecedor para CEP_NUMBER (padr√£o avan√ßado)
            cep_pattern = Pattern(name="CepPattern", regex=r"\b(\d{5}-?\d{3}|\d{2}\.\d{3}-?\d{3})\b", score=0.80) 
            cep_recognizer = PatternRecognizer(
                supported_entity="CEP_NUMBER", 
                name="CustomCepRecognizer", 
                patterns=[cep_pattern], 
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(cep_recognizer)

            # Reconhecedor para ESTADO_CIVIL
            if self.estado_civil:
                estado_civil_patterns = [Pattern(name=f"estado_civil_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in self.estado_civil]
                ec_recognizer = PatternRecognizer(
                    supported_entity="ESTADO_CIVIL", 
                    name="EstadoCivilRecognizer", 
                    patterns=estado_civil_patterns, 
                    supported_language="pt"
                )
                self.analyzer.registry.add_recognizer(ec_recognizer)

            # Reconhecedor para ORGANIZACOES_CONHECIDAS
            if self.organizacoes_conhecidas:
                org_patterns = [Pattern(name=f"org_{t.lower()}", regex=rf"(?i)\b{re.escape(t)}\b", score=0.99) for t in self.organizacoes_conhecidas]
                org_recognizer = PatternRecognizer(
                    supported_entity="ORGANIZACAO_CONHECIDA", 
                    name="OrganizacaoConhecidaRecognizer", 
                    patterns=org_patterns, 
                    supported_language="pt"
                )
                self.analyzer.registry.add_recognizer(org_recognizer)
            
            # Reconhecedor para Sobrenomes Frequentes (da lista externa)
            if self.sobrenomes_comuns:
                surnames_patterns = [Pattern(name=f"surname_{s.lower().replace(' ', '_')}", regex=rf"(?i)\b{re.escape(s)}\b", score=0.97) for s in self.sobrenomes_comuns]
                surnames_recognizer = PatternRecognizer(
                    supported_entity="PERSON", 
                    name="BrazilianCommonSurnamesRecognizer", 
                    patterns=surnames_patterns, 
                    supported_language="pt"
                )
                self.analyzer.registry.add_recognizer(surnames_recognizer)
            
            # Reconhecedor para SIAPE (Sistema Integrado de Administra√ß√£o de Recursos Humanos)
            siape_patterns = [
                Pattern(name="siape_formatado", regex=r"\bSIAPE\s*(?:n[¬∫o]\s*)?\d{5,10}\b", score=0.98),
                Pattern(name="siape_apenas_numeros", regex=r"\b\d{5,10}\b", score=0.85)
            ]
            siape_recognizer = PatternRecognizer(
                supported_entity="SIAPE",
                name="SIAPERecognizer",
                patterns=siape_patterns,
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(siape_recognizer)

            # Reconhecedor para RG
            rg_patterns = [
                Pattern(name="rg_formatado", regex=r"\bRG\s*(?:n[¬∫o]\s*)?\d{5,12}(-\d)?\b", score=0.98),
                Pattern(name="rg_apenas_numeros", regex=r"\b\d{5,12}(-\d)?\b", score=0.85)
            ]
            rg_recognizer = PatternRecognizer(
                supported_entity="RG",
                name="RGRecognizer",
                patterns=rg_patterns,
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(rg_recognizer)

            # Reconhecedor para CNH
            cnh_patterns = [
                Pattern(name="cnh_formatado", regex=r"\bCNH\s*(?:n[¬∫o]\s*)?\d{9,12}\b", score=0.98),
                Pattern(name="cnh_apenas_numeros", regex=r"\b\d{9,12}\b", score=0.85)
            ]
            cnh_recognizer = PatternRecognizer(
                supported_entity="CNH",
                name="CNHRecognizer",
                patterns=cnh_patterns,
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(cnh_recognizer)

            # Reconhecedor para CI
            ci_patterns = [
                Pattern(name="ci_formatado", regex=r"\bCI\s*(?:n[¬∫o]\s*)?\d{5,12}\b", score=0.98),
                Pattern(name="ci_apenas_numeros", regex=r"\b\d{5,12}\b", score=0.85)
            ]
            ci_recognizer = PatternRecognizer(
                supported_entity="CI",
                name="CIRecognizer",
                patterns=ci_patterns,
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(ci_recognizer)
            
            # Reconhecedor para IDs de Documento/Processo/Benef√≠cio (REFINADO)
            id_documento_patterns = [
                Pattern(name="numero_beneficio_nb_formatado", regex=r"\bNB\s*\d{1,3}(\.?\d{3}){2}-[\dX]\b", score=0.98),
                Pattern(name="id_numerico_longo_pje", regex=r"\b\d{10,25}\b", score=0.97), 
                Pattern(name="id_prefixo_numerico", regex=r"\bID\s*\d{8,12}\b", score=0.97),
                Pattern(name="numero_rg_completo", regex=r"\bRG\s*(?:n¬∫|n\.)?\s*[\d.X-]+(?:-\d¬™\s*VIA)?\s*-\s*[A-Z]{2,3}\/[A-Z]{2}\b", score=0.98),
                Pattern(name="numero_rg_simples", regex=r"\bRG\s*(?:n¬∫|n\.)?\s*[\d.X-]+\b", score=0.97),
                Pattern(name="numero_processo_cnj", regex=r"\b\d{7}-\d{2}\.\d{4}\.\d\.\d{2}\.\d{4}\b", score=0.95),
                Pattern(name="numero_rnm", regex=r"\bRNM\s*(?:n¬∫|n\.)?\s*[A-Z0-9]{7,15}\b", score=0.98),
                Pattern(name="numero_crm", regex=r"\bCRM\s*[A-Z]{2}\s*-\s*\d{1,6}\b", score=0.98)
            ]
            id_documento_recognizer = PatternRecognizer(
                supported_entity="ID_DOCUMENTO", 
                name="IdDocumentoRecognizer",
                patterns=id_documento_patterns,
                supported_language="pt"
            )
            self.analyzer.registry.add_recognizer(id_documento_recognizer)
            
            # Reconhecedor para Termos Comuns (whitelist)
            if self.termos_comuns:
                termos_comuns_recognizer = PatternRecognizer(
                    supported_entity="LEGAL_OR_COMMON_TERM",
                    name="LegalOrCommonTermRecognizer",
                    deny_list=self.termos_comuns,
                    supported_language="pt",
                    deny_list_score=0.99
                )
                self.analyzer.registry.add_recognizer(termos_comuns_recognizer)
            
            print("‚úÖ Reconhecedores personalizados avan√ßados para portugu√™s brasileiro adicionados!")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao adicionar reconhecedores personalizados: {e}")
    
    def extrair_texto_pdf(self, caminho_arquivo: str) -> str:
        """Extrai texto de um arquivo PDF"""
        try:
            with open(caminho_arquivo, 'rb') as arquivo:
                leitor_pdf = PyPDF2.PdfReader(arquivo)
                texto = ""
                
                for pagina in leitor_pdf.pages:
                    texto += pagina.extract_text() + "\n"
                
                return texto.strip()
        except Exception as e:
            raise Exception(f"Erro ao extrair texto do PDF: {str(e)}")
    
    def detectar_entidades(self, texto: str) -> list:
        """Detecta entidades PII no texto usando Presidio Analyzer com configura√ß√£o avan√ßada"""
        try:
            # Usar configura√ß√£o avan√ßada com todas as entidades personalizadas
            resultados = self.analyzer.analyze(
                text=texto,
                language='pt'
            )
            
            return resultados
        except Exception as e:
            raise Exception(f"Erro ao detectar entidades: {str(e)}")
    
    def obter_operadores_anonimizacao(self):
        return {
            "DEFAULT": OperatorConfig("keep"),
            "PERSON": OperatorConfig("replace", {"new_value": "<NOME>"}),
            "LOCATION": OperatorConfig("replace", {"new_value": "<ENDERECO>"}),
            "EMAIL_ADDRESS": OperatorConfig("replace", {"new_value": "<EMAIL>"}),
            "PHONE_NUMBER": OperatorConfig("mask", {"type": "mask", "masking_char": "*", "chars_to_mask": 4, "from_end": True}),
            "CPF": OperatorConfig("replace", {"new_value": "***"}),
            "DATE_TIME": OperatorConfig("keep"), 
            "OAB_NUMBER": OperatorConfig("replace", {"new_value": "<OAB>"}),
            "CEP_NUMBER": OperatorConfig("replace", {"new_value": "***"}),
            "ESTADO_CIVIL": OperatorConfig("keep"),
            "ORGANIZACAO_CONHECIDA": OperatorConfig("keep"),
            "ID_DOCUMENTO": OperatorConfig("keep"), 
            "LEGAL_OR_COMMON_TERM": OperatorConfig("keep"),
            "SAFE_LOCATION": OperatorConfig("keep"),
            "LEGAL_HEADER": OperatorConfig("keep"),
            "CNH": OperatorConfig("replace", {"new_value": "***"}),
            "SIAPE": OperatorConfig("replace", {"new_value": "***"}),
            "RG": OperatorConfig("replace", {"new_value": "***"}),
            "CI": OperatorConfig("replace", {"new_value": "***"})
        }
    
    def anonimizar_texto(self, texto: str, entidades_detectadas: list = None) -> str:
        """Anonimiza o texto substituindo entidades PII detectadas com operadores avan√ßados"""
        try:
            # Se n√£o foram fornecidas entidades, detectar automaticamente
            if entidades_detectadas is None:
                entidades_detectadas = self.detectar_entidades(texto)
            
            # Obter operadores de anonimiza√ß√£o completos
            operadores = self.obter_operadores_anonimizacao()
            
            # Aplicar anonimiza√ß√£o
            resultado = self.anonymizer.anonymize(
                text=texto,
                analyzer_results=entidades_detectadas,
                operators=operadores
            )
            
            return resultado.text
        except Exception as e:
            raise Exception(f"Erro ao anonimizar texto: {str(e)}")
    
    def processar_documento(self, caminho_arquivo: str, modelo: str, chave_api: str = "") -> str:
        """Processa um documento para anonimiza√ß√£o usando Presidio com configura√ß√£o avan√ßada"""
        try:
            # Validar arquivo
            if not self.validar_arquivo(caminho_arquivo):
                return "‚ùå Tipo de arquivo n√£o suportado. Use PDF, TXT ou DOCX."
            
            # Extrair texto do PDF
            texto_original = self.extrair_texto_pdf(caminho_arquivo)
            
            if not texto_original.strip():
                return "‚ùå N√£o foi poss√≠vel extrair texto do documento."
            
            # Detectar entidades PII com configura√ß√£o avan√ßada
            entidades_detectadas = self.detectar_entidades(texto_original)
            
            # Anonimizar texto com operadores avan√ßados
            texto_anonimizado = self.anonimizar_texto(texto_original, entidades_detectadas)
            
            # Contar entidades detectadas por tipo
            contagem_por_tipo = {}
            for entidade in entidades_detectadas:
                tipo = entidade.entity_type
                contagem_por_tipo[tipo] = contagem_por_tipo.get(tipo, 0) + 1
            
            # Preparar resultado detalhado
            resultado = f"""
‚úÖ Documento processado com sucesso usando Microsoft Presidio Avan√ßado!

üìÑ Arquivo: {os.path.basename(caminho_arquivo)}
ü§ñ Modelo: {modelo}
üîë API: {'Configurada' if chave_api else 'N√£o configurada'}

üìã Status: Anonimiza√ß√£o conclu√≠da
üéØ Total de entidades detectadas: {len(entidades_detectadas)}

üìä Detalhamento por tipo:
"""
            
            for tipo, contagem in contagem_por_tipo.items():
                resultado += f"   ‚Ä¢ {tipo}: {contagem}\n"
            
            resultado += f"""
üîÑ Substitui√ß√µes realizadas: {len(entidades_detectadas)}

üìù TEXTO ORIGINAL:
{texto_original}

üîí TEXTO ANONIMIZADO:
{texto_anonimizado}

üí° Documento anonimizado usando Microsoft Presidio com configura√ß√£o avan√ßada para portugu√™s brasileiro.
   Todas as informa√ß√µes pessoais foram substitu√≠das por marcadores seguros.
   
üîß Funcionalidades ativas:
   ‚Ä¢ Reconhecedores regex avan√ßados para documentos brasileiros
   ‚Ä¢ Listas de termos espec√≠ficos (estados, cabe√ßalhos legais, sobrenomes)
   ‚Ä¢ Operadores de anonimiza√ß√£o inteligentes
   ‚Ä¢ Suporte completo ao idioma portugu√™s
            """
            
            return resultado
            
        except Exception as e:
            return f"‚ùå Erro ao processar documento: {str(e)}"
    
    def validar_arquivo(self, caminho: str) -> bool:
        """Valida se o arquivo √© suportado"""
        extensoes_validas = ['.pdf', '.txt', '.docx']
        return any(caminho.lower().endswith(ext) for ext in extensoes_validas)

# üîí AnonimizaJud - Gradio

Sistema inteligente de anonimiza√ß√£o de documentos jur√≠dicos brasileiros utilizando IA (Microsoft Presidio) para proteger dados sens√≠veis.

## Principais Funcionalidades

- **Anonimiza√ß√£o autom√°tica** de nomes, endere√ßos, CPFs, CEPs, SIAPE, RG, CNH, CI, e e-mails.
- **Substitui√ß√£o padronizada:**  
  - CPFs, CEPs, SIAPE, RG, CNH e CI s√£o sempre substitu√≠dos por `***`.
  - Nomes por `<NOME>`, endere√ßos por `<ENDERECO>`, e-mails por `<EMAIL>`.